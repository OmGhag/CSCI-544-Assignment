{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed114291",
   "metadata": {},
   "source": [
    "CSCI 544 - Homework 2 <br>\n",
    "Neural Networks for Sentiment Analysis <br>\n",
    "Python Version: 3.13.9 <br>\n",
    "Library: PyTorch <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf55a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.10.0+cu128\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, bigrams\n",
    "\n",
    "# Gensim for Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4777d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndownloaded the dataset locally through the above links using terminal wget command    \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n",
    "#          https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\n",
    "\n",
    "\"\"\"\n",
    "downloaded the dataset locally through the above links using terminal wget command    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49332d5",
   "metadata": {},
   "source": [
    "# Question 1: Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789ccb3",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697dc82",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a99bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data/amazon_reviews_us_Office_Products_v1_00.tsv.gz', sep='\\t', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32dafe2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640254, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2313b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1          US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2          US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0     Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1          Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2  Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          1.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1  Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                      but I am sure I will like it.   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                     Great product.  2015-08-31  \n",
       "1  What's to say about this commodity item except...  2015-08-31  \n",
       "2    Haven't used yet, but I am sure I will like it.  2015-08-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439a171",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e59124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3a1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str\n",
      "<StringArray>\n",
      "['5', '1', '4', '2', '3', '2015-06-05', '2015-02-11', nan, '2014-02-14']\n",
      "Length: 9, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(df['star_rating'].dtype)\n",
    "print(df['star_rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74b6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[ 5.  1.  4.  2.  3. nan]\n"
     ]
    }
   ],
   "source": [
    "df['star_rating'] = pd.to_numeric(df['star_rating'], errors='coerce')\n",
    "print(df['star_rating'].dtype)\n",
    "print(df['star_rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d74cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['review_body', 'star_rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c49102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640080, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e010137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_body  star_rating\n",
      "0                                     Great product.          5.0\n",
      "1  What's to say about this commodity item except...          5.0\n",
      "2    Haven't used yet, but I am sure I will like it.          5.0\n",
      "star_rating\n",
      "1.0     306967\n",
      "2.0     138381\n",
      "3.0     193680\n",
      "4.0     418348\n",
      "5.0    1582704\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[['review_body', 'star_rating']]  # selecting only relevant columns\n",
    "print(df.head(3))\n",
    "print(df['star_rating'].value_counts().sort_index())  # checking distribution of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe991cb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Relabeling and Sampling\n",
    " \n",
    "First form three classes and print their statistics. Then randomly select 250,000 reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5972d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1: 50000 reviews sampled\n",
      "Rating 2: 50000 reviews sampled\n",
      "Rating 3: 50000 reviews sampled\n",
      "Rating 4: 50000 reviews sampled\n",
      "Rating 5: 50000 reviews sampled\n"
     ]
    }
   ],
   "source": [
    "balanced_dfs = []\n",
    "\n",
    "for rating in [1, 2, 3, 4, 5]:\n",
    "    rating_df = df[df['star_rating'] == rating]\n",
    "    \n",
    "    if len(rating_df) >= 50000:\n",
    "        sampled = rating_df.sample(n=50000, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        print(f\"Warning: Only {len(rating_df)} reviews available for rating {rating}\")\n",
    "        sampled = rating_df\n",
    "    \n",
    "    balanced_dfs.append(sampled)\n",
    "    print(f\"Rating {rating}: {len(sampled)} reviews sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b7a5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "1.0    50000\n",
       "2.0    50000\n",
       "3.0    50000\n",
       "4.0    50000\n",
       "5.0    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all\n",
    "df_balanced = pd.concat(balanced_dfs, ignore_index=True)\n",
    "print(df_balanced.shape)\n",
    "df_balanced['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a278b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    100000\n",
      "2    100000\n",
      "3     50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_ternary_label(rating):\n",
    "    \"\"\"\n",
    "    rating > 3 â†’ class 1 (Positive)\n",
    "    rating < 3 â†’ class 2 (Negative)\n",
    "    rating = 3 â†’ class 3 (Neutral)\n",
    "    \"\"\"\n",
    "    if rating > 3:\n",
    "        return 1  # Positive\n",
    "    elif rating < 3:\n",
    "        return 2  # Negative\n",
    "    else:\n",
    "        return 3  # Neutral\n",
    "\n",
    "# Fix your labels\n",
    "df_balanced['label'] = df_balanced['star_rating'].apply(create_ternary_label)\n",
    "print(df_balanced['label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d277acc",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2aed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTIONS_MAP = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"amn't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"daren't\": \"dare not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"everyone's\": \"everyone is\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"I would\",\n",
    "    \"i'd've\": \"I would have\",\n",
    "    \"i'll\": \"I will\",\n",
    "    \"i'll've\": \"I will have\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"innit\": \"is it not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"ne'er\": \"never\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"o'er\": \"over\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"outta\": \"out of\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"somebody's\": \"somebody is\",\n",
    "    \"someone's\": \"someone is\",\n",
    "    \"something's\": \"something is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"tis\": \"it is\",\n",
    "    \"twas\": \"it was\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"whatcha\": \"what are you\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d8ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  I can't do this. She's going to the market. Y'all've been great!\n",
      "Expanded Text:  I cannot do this. She is going to the market. You all have been great!\n"
     ]
    }
   ],
   "source": [
    "def remove_contractions(text):\n",
    "    # Sort contractions by length (longest first) to handle compound contractions\n",
    "    contractions_sorted = sorted(CONTRACTIONS_MAP.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Build pattern with word boundaries\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in contractions_sorted) + r')\\b', \n",
    "                        flags=re.IGNORECASE)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        match_lower = match.lower()\n",
    "        \n",
    "        if match_lower in CONTRACTIONS_MAP:\n",
    "            expanded = CONTRACTIONS_MAP[match_lower]\n",
    "            \n",
    "            # Preserve original capitalization\n",
    "            if match[0].isupper():\n",
    "                expanded = expanded[0].upper() + expanded[1:]\n",
    "            \n",
    "            return expanded\n",
    "        \n",
    "        return match\n",
    "    \n",
    "    # Keep expanding until no more contractions found\n",
    "    prev_text = \"\"\n",
    "    while prev_text != text:\n",
    "        prev_text = text\n",
    "        text = pattern.sub(expand_match, text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "sample_text = \"I can't do this. She's going to the market. Y'all've been great!\"\n",
    "print(\"Original Text: \", sample_text)\n",
    "expanded_text = remove_contractions(sample_text)\n",
    "print(\"Expanded Text: \", expanded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae0e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Expand contractions\n",
    "    text = remove_contractions(text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d8e6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(341.193312)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_length_before = df_balanced['review_body'].str.len().mean()\n",
    "avg_length_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca84cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['review_body'] = df_balanced['review_body'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6178b84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(324.048708)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_length_after = df_balanced['review_body'].str.len().mean()\n",
    "avg_length_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b27bc896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    i purchased these tabs on a whim to put up som...\n",
      "1       returned it too much garbage involved in setup\n",
      "2    my upholstered living room chairs are not part...\n",
      "Name: review_body, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(df_balanced['review_body'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730ffaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6428"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df, CONTRACTIONS_MAP\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735d26b",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f34482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Convert treebank POS tags to WordNet POS tags\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default to noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f33fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize_with_pos(text):\n",
    "    \"\"\"\n",
    "    Enhanced lemmatization that tries multiple POS tags for better results\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    \n",
    "    if not words:\n",
    "        return \"\"\n",
    "    \n",
    "    # POS tag the available text\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    lemmatized = []\n",
    "    for word, pos in pos_tags:\n",
    "        # Get primary WordNet POS\n",
    "        primary_pos = get_wordnet_pos(pos)\n",
    "        \n",
    "        # Try lemmatizing with the detected POS\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, primary_pos)\n",
    "        \n",
    "        # If word didn't change and it might be a verb, try verb lemmatization\n",
    "        if lemmatized_word == word and primary_pos != wordnet.VERB:\n",
    "            verb_form = lemmatizer.lemmatize(word, wordnet.VERB)\n",
    "            # Use verb form if it's different (likely was actually a verb)\n",
    "            if verb_form != word:\n",
    "                lemmatized_word = verb_form\n",
    "        \n",
    "        lemmatized.append(lemmatized_word)\n",
    "    \n",
    "    return ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff66cc",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fefa270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: this is not a good product and i do not recommend it\n",
      "After stopword removal: not good product not recommend\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords but keep negation words\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # CRITICAL: Keep negation words for sentiment analysis\n",
    "    negations = {\n",
    "        'no', 'not', 'nor', 'never', 'neither', 'nobody', 'nothing', \n",
    "        'nowhere', 'none', 'hardly', 'scarcely', 'barely'\n",
    "    }\n",
    "    # Remove negation words from stopwords list\n",
    "    stop_words = stop_words - negations\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Test it on a sample\n",
    "sample_text = \"this is not a good product and i do not recommend it\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"After stopword removal:\", remove_stopwords(sample_text))\n",
    "# Should keep \"not\" in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c033fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before preprocessing:\n",
      "0    i purchased these tabs on a whim to put up som...\n",
      "1       returned it too much garbage involved in setup\n",
      "2    my upholstered living room chairs are not part...\n",
      "Name: review_body, dtype: str\n",
      "Average length before preprocessing: 324.0487\n"
     ]
    }
   ],
   "source": [
    "samples_before_preprocessing = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples before preprocessing:\")\n",
    "print(samples_before_preprocessing)\n",
    "avg_length_before_preprocessing = df_balanced['review_body'].str.len().mean()\n",
    "print(f\"Average length before preprocessing:{ avg_length_before_preprocessing: .4f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffa0517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before removing stop words:\n",
      "0    i purchased these tabs on a whim to put up som...\n",
      "1       returned it too much garbage involved in setup\n",
      "2    my upholstered living room chairs are not part...\n",
      "Name: review_body, dtype: str\n",
      "Average length before removing stop words: 324.048708\n",
      "Samples after removing stop words:\n",
      "0    purchased tabs whim put movie posters used fou...\n",
      "1                 returned much garbage involved setup\n",
      "2    upholstered living room chairs not particularl...\n",
      "Name: review_body, dtype: str\n",
      "Average length after removing stop words: 209.308632\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# Save before preprocessing\n",
    "samples_before_stopwords_removal = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples before removing stop words:\")\n",
    "print(samples_before_stopwords_removal)\n",
    "avg_length_before_stopwords_removal = df_balanced['review_body'].str.len().mean()\n",
    "print(\"Average length before removing stop words:\", avg_length_before_stopwords_removal)\n",
    "# Now remove stop words\n",
    "# Apply stopword removal (keeping negations)\n",
    "df_balanced['review_body'] = df_balanced['review_body'].apply(remove_stopwords)\n",
    "\n",
    "# After all preprocessing\n",
    "samples_after_stopwords_removal = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples after removing stop words:\")\n",
    "print(samples_after_stopwords_removal)\n",
    "avg_length_after_stopwords_removal = df_balanced['review_body'].str.len().mean()\n",
    "print(\"Average length after removing stop words:\", avg_length_after_stopwords_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0769f",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f22ae11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before lemmatization:\n",
      "0    purchased tabs whim put movie posters used fou...\n",
      "1                 returned much garbage involved setup\n",
      "2    upholstered living room chairs not particularl...\n",
      "Name: review_body, dtype: str\n",
      "Average length before lemmatization: 209.308632\n",
      "Samples after lemmatization:\n",
      "0    purchase tab whim put movie poster use four in...\n",
      "1                    return much garbage involve setup\n",
      "2    upholster live room chair not particularly big...\n",
      "Name: review_body, dtype: str\n",
      "Average length after lemmatization: 197.9258\n"
     ]
    }
   ],
   "source": [
    "#save before lemmatization\n",
    "samples_before_lemmatization = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples before lemmatization:\")\n",
    "print(samples_before_lemmatization)\n",
    "avg_length_before_lemmatization = df_balanced['review_body'].str.len().mean()\n",
    "print(\"Average length before lemmatization:\", avg_length_before_lemmatization)\n",
    "\n",
    "# Apply lemmatization\n",
    "df_balanced['review_body'] = df_balanced['review_body'].apply(lemmatize_with_pos)\n",
    "\n",
    "# After lemmatization\n",
    "samples_after_lemmatization = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples after lemmatization:\")\n",
    "print(samples_after_lemmatization)\n",
    "avg_length_after_lemmatization = df_balanced['review_body'].str.len().mean()\n",
    "print(\"Average length after lemmatization:\", avg_length_after_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4caa91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4e4bda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples after preprocessing:\n",
      "0    purchase tab whim put movie poster use four in...\n",
      "1                    return much garbage involve setup\n",
      "2    upholster live room chair not particularly big...\n",
      "Name: review_body, dtype: str\n",
      "Average length after preprocessing:  197.9258\n"
     ]
    }
   ],
   "source": [
    "samples_after_preprocessing = df_balanced['review_body'].head(3).copy()\n",
    "print(\"Samples after preprocessing:\")\n",
    "print(samples_after_preprocessing)\n",
    "avg_length_after_preprocessing = df_balanced['review_body'].str.len().mean()\n",
    "print(f\"Average length after preprocessing: {avg_length_after_preprocessing: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac55a9f",
   "metadata": {},
   "source": [
    "# Question 2: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b73da",
   "metadata": {},
   "source": [
    "#### (a) loading pretrained \"word2vec-google-news-300â€ Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90db0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab33b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3,000,000\n",
      "Vector dimensionality: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {len(pretrained_w2v.key_to_index):,}\")\n",
    "print(f\"Vector dimensionality: {pretrained_w2v.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56e1b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results:\n",
      "  queen           similarity: 0.7118\n",
      "  monarch         similarity: 0.6190\n",
      "  princess        similarity: 0.5902\n",
      "  crown_prince    similarity: 0.5499\n",
      "  prince          similarity: 0.5377\n"
     ]
    }
   ],
   "source": [
    "# SEMANTIC SIMILARITY TEST 1: King - Man + Woman\n",
    "try:\n",
    "    result = pretrained_w2v.most_similar(\n",
    "        positive=['king', 'woman'], \n",
    "        negative=['man'], \n",
    "        topn=5\n",
    "    )\n",
    "    print(\"\\nTop 5 results:\")\n",
    "    for word, score in result:\n",
    "        print(f\"  {word:15} similarity: {score:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb72f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity(excellent, outstanding) = 0.5567\n",
      "\n",
      "Words most similar to 'excellent':\n",
      "  terrific        similarity: 0.7410\n",
      "  superb          similarity: 0.7063\n",
      "  exceptional     similarity: 0.6815\n",
      "  fantastic       similarity: 0.6803\n",
      "  good            similarity: 0.6443\n"
     ]
    }
   ],
   "source": [
    "# SEMANTIC SIMILARITY TEST 2: excellent ~ outstanding\n",
    "try:\n",
    "    similarity = pretrained_w2v.similarity('excellent', 'outstanding')\n",
    "    print(f\"\\nSimilarity(excellent, outstanding) = {similarity:.4f}\")\n",
    "    \n",
    "    # Show most similar words to 'excellent'\n",
    "    print(\"\\nWords most similar to 'excellent':\")\n",
    "    similar_words = pretrained_w2v.most_similar('excellent', topn=5)\n",
    "    for word, score in similar_words:\n",
    "        print(f\"  {word:15} similarity: {score:.4f}\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1fb1a",
   "metadata": {},
   "source": [
    "#### (b) Training custom Word2Vec on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94c93b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing tokenized reviews...\n",
      "Number of reviews: 250,000\n",
      "Sample tokenized review:\n",
      "  ['purchase', 'tab', 'whim', 'put', 'movie', 'poster', 'use', 'four', 'inch', 'tab', 'poster', 'not', 'job', 'poster', 'stay', 'day', 'one', 'right', 'start', 'fall']...\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenized reviews for Word2Vec training\n",
    "print(\"\\nPreparing tokenized reviews...\")\n",
    "# Use your preprocessed reviews (already cleaned and lemmatized)\n",
    "tokenized_reviews = [review.split() for review in df_balanced['review_body']]\n",
    "\n",
    "print(f\"Number of reviews: {len(tokenized_reviews):,}\")\n",
    "print(f\"Sample tokenized review:\")\n",
    "print(f\"  {tokenized_reviews[0][:20]}...\")  # Show first 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1104d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Vocabulary size: 13,116\n",
      "Vector dimensionality: 300\n",
      "\n",
      "Model saved to 'custom_word2vec.model'\n"
     ]
    }
   ],
   "source": [
    "custom_w2v = Word2Vec(\n",
    "    sentences=tokenized_reviews,\n",
    "    vector_size=300,      # embedding size = 300\n",
    "    window=11,            # window size = 11\n",
    "    min_count=10,         # minimum word count = 10\n",
    "    workers= multiprocessing.cpu_count(),            # use all available CPU cores\n",
    "    seed=RANDOM_STATE,    # for reproducibility\n",
    "    epochs=10,            # training epochs\n",
    "    sg=0,                 # CBOW (0) or Skip-gram (1)\n",
    "    negative=5            # negative sampling\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Vocabulary size: {len(custom_w2v.wv.key_to_index):,}\")\n",
    "print(f\"Vector dimensionality: {custom_w2v.wv.vector_size}\")\n",
    "\n",
    "# Save the model\n",
    "custom_w2v.save('custom_word2vec.model')\n",
    "print(\"\\nModel saved to 'custom_word2vec.model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "864c169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. VOCABULARY SIZE:\n",
      "   Pretrained (Google News): 3,000,000 words\n",
      "   Custom (Office Reviews):  13,116 words\n",
      "   Ratio: 228.7x larger\n"
     ]
    }
   ],
   "source": [
    "# Compare vocabulary sizes\n",
    "print(\"\\n1. VOCABULARY SIZE:\")\n",
    "print(f\"   Pretrained (Google News): {len(pretrained_w2v.key_to_index):,} words\")\n",
    "print(f\"   Custom (Office Reviews):  {len(custom_w2v.wv.key_to_index):,} words\")\n",
    "print(f\"   Ratio: {len(pretrained_w2v.key_to_index) / len(custom_w2v.wv.key_to_index):.1f}x larger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8566490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. TRAINING DATA:\n",
      "   Pretrained: ~100 billion words from Google News\n",
      "   Custom: 250,000 Amazon office product reviews\n"
     ]
    }
   ],
   "source": [
    "# Compare training corpus\n",
    "print(\"\\n2. TRAINING DATA:\")\n",
    "print(\"   Pretrained: ~100 billion words from Google News\")\n",
    "print(\"   Custom: 250,000 Amazon office product reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "656813c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DOMAIN-SPECIFIC VOCABULARY:\n",
      "\n",
      "   Word            Pretrained      Custom         \n",
      "   ---------------------------------------------\n",
      "   product         âœ“               âœ“              \n",
      "   quality         âœ“               âœ“              \n",
      "   price           âœ“               âœ“              \n",
      "   shipping        âœ“               âœ—              \n",
      "   recommend       âœ“               âœ“              \n",
      "   excellent       âœ“               âœ“              \n",
      "   terrible        âœ“               âœ“              \n",
      "   refund          âœ“               âœ“              \n",
      "   packaging       âœ“               âœ—              \n",
      "   defective       âœ“               âœ“              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test domain-specific words\n",
    "print(\"\\n3. DOMAIN-SPECIFIC VOCABULARY:\")\n",
    "test_words = ['product', 'quality', 'price', 'shipping', 'recommend', \n",
    "              'excellent', 'terrible', 'refund', 'packaging', 'defective']\n",
    "\n",
    "print(f\"\\n   {'Word':<15} {'Pretrained':<15} {'Custom':<15}\")\n",
    "print(\"   \" + \"-\" * 45)\n",
    "\n",
    "for word in test_words:\n",
    "    pretrained_exists = word in pretrained_w2v\n",
    "    custom_exists = word in custom_w2v.wv\n",
    "    print(f\"   {word:<15} {'âœ“' if pretrained_exists else 'âœ—':<15} {'âœ“' if custom_exists else 'âœ—':<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "789d6294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. SEMANTIC SIMILARITY COMPARISON:\n",
      "   Testing word pairs from our domain:\n",
      "\n",
      "   Word Pair                 Pretrained      Custom         \n",
      "   -------------------------------------------------------\n",
      "   good - excellent            0.6443          0.5802         \n",
      "   bad - terrible             0.6829          0.4542         \n",
      "   buy - purchase             0.7640          0.7336         \n",
      "   product - item                 0.2570          0.4925         \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare semantic similarities\n",
    "print(\"\\n4. SEMANTIC SIMILARITY COMPARISON:\")\n",
    "print(\"   Testing word pairs from our domain:\")\n",
    "\n",
    "word_pairs = [\n",
    "    ('good', 'excellent'),\n",
    "    ('bad', 'terrible'),\n",
    "    ('buy', 'purchase'),\n",
    "    ('product', 'item'),\n",
    "]\n",
    "\n",
    "print(f\"\\n   {'Word Pair':<25} {'Pretrained':<15} {'Custom':<15}\")\n",
    "print(\"   \" + \"-\" * 55)\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    try:\n",
    "        sim_pre = pretrained_w2v.similarity(word1, word2)\n",
    "    except KeyError:\n",
    "        sim_pre = None\n",
    "    \n",
    "    try:\n",
    "        sim_cust = custom_w2v.wv.similarity(word1, word2)\n",
    "    except KeyError:\n",
    "        sim_cust = None\n",
    "    \n",
    "    pre_str = f\"{sim_pre:.4f}\" if sim_pre else \"N/A\"\n",
    "    cust_str = f\"{sim_cust:.4f}\" if sim_cust else \"N/A\"\n",
    "    \n",
    "    print(f\"   {word1} - {word2:<20} {pre_str:<15} {cust_str:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef20c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. OUT-OF-VOCABULARY (OOV) ANALYSIS:\n",
      "   Analyzing how many words from our reviews are missing from each model...\n",
      "\n",
      "   Total words analyzed: 34,605\n",
      "   Pretrained OOV rate: 3.13%\n",
      "   Custom OOV rate: 2.95%\n"
     ]
    }
   ],
   "source": [
    "# Test Out-of-Vocabulary (OOV) rate\n",
    "print(\"\\n5. OUT-OF-VOCABULARY (OOV) ANALYSIS:\")\n",
    "print(\"   Analyzing how many words from our reviews are missing from each model...\")\n",
    "\n",
    "# Sample 1000 reviews\n",
    "sample_reviews = df_balanced['review_body'].sample(1000, random_state=RANDOM_STATE)\n",
    "\n",
    "oov_pretrained = 0\n",
    "oov_custom = 0\n",
    "total_words = 0\n",
    "\n",
    "for review in sample_reviews:\n",
    "    words = review.split()\n",
    "    for word in words:\n",
    "        total_words += 1\n",
    "        if word not in pretrained_w2v:\n",
    "            oov_pretrained += 1\n",
    "        if word not in custom_w2v.wv:\n",
    "            oov_custom += 1\n",
    "\n",
    "print(f\"\\n   Total words analyzed: {total_words:,}\")\n",
    "print(f\"   Pretrained OOV rate: {oov_pretrained/total_words*100:.2f}%\")\n",
    "print(f\"   Custom OOV rate: {oov_custom/total_words*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcb5d1",
   "metadata": {},
   "source": [
    "WHICH MODEL ENCODES SEMANTIC SIMILARITIES BETTER?<br>\n",
    "<br>\n",
    "Based on our experiments:<br>\n",
    "\n",
    "âœ… PRETRAINED WORD2VEC is better for GENERAL semantic relationships:\n",
    "   - Higher similarity scores for general analogies (king-queen)\n",
    "   - Better captures broad semantic patterns (good-excellent, bad-terrible)\n",
    "   - 228x larger vocabulary provides richer representations\n",
    "   \n",
    "âœ… CUSTOM WORD2VEC is better for DOMAIN-SPECIFIC patterns:\n",
    "   - Lower OOV rate (2.95% vs 3.13%) on our reviews\n",
    "   - Better similarity for domain terms (product-item: 0.49 vs 0.26)\n",
    "   - Tuned specifically to office product review language\n",
    "   \n",
    "ðŸ“Š PREDICTION FOR Q3:\n",
    "   We expect pretrained features to perform BETTER overall because:\n",
    "   - Richer semantic representations from 100B word corpus\n",
    "   - Better generalization to unseen patterns\n",
    "   - Lower OOV on general English vocabulary\n",
    "   \n",
    "   However, custom features may be COMPETITIVE because:\n",
    "   - Domain-specific vocabulary alignment\n",
    "   - Lower OOV within our specific dataset\n",
    "   - Tuned to sentiment patterns in product reviews\n",
    "   \n",
    "We will test this hypothesis in Question 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02192512",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "172c8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(review, model, is_custom=False):\n",
    "    \"\"\"\n",
    "    Get the average Word2Vec vector for a review.\n",
    "    If is_custom=True, use model.wv for custom Word2Vec.\n",
    "    \"\"\"\n",
    "    words = review.split()\n",
    "    vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            if is_custom:\n",
    "                vectors.append(model.wv[word])\n",
    "            else:\n",
    "                vectors.append(model[word])\n",
    "        except KeyError:\n",
    "            continue  # Skip OOV words\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no words found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1771bbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test review: purchase tab whim put movie poster use four inch tab poster not job poster stay day one right start ...\n",
      "\n",
      "Pretrained vector shape: (300,)\n",
      "Custom vector shape: (300,)\n",
      "First 5 values (pretrained): [ 0.04097428 -0.00591943  0.01230277  0.14582284 -0.04860171]\n"
     ]
    }
   ],
   "source": [
    "test_review = df_balanced['review_body'].iloc[0]\n",
    "print(f\"Test review: {test_review[:100]}...\")\n",
    "\n",
    "vec_pretrained = get_average_word2vec(test_review, pretrained_w2v, is_custom=False)\n",
    "vec_custom = get_average_word2vec(test_review, custom_w2v, is_custom=True)\n",
    "\n",
    "print(f\"\\nPretrained vector shape: {vec_pretrained.shape}\")\n",
    "print(f\"Custom vector shape: {vec_custom.shape}\")\n",
    "print(f\"First 5 values (pretrained): {vec_pretrained[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b6681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['pretrained_vec'] = df_balanced['review_body'].apply(\n",
    "    lambda review: get_average_word2vec(review, pretrained_w2v, is_custom=False)\n",
    ")\n",
    "\n",
    "df_balanced['custom_vec'] = df_balanced['review_body'].apply(\n",
    "    lambda review: get_average_word2vec(review, custom_w2v, is_custom=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3f77ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Memory-efficient dataset that generates features on-the-fly.\n",
    "    Supports: averaged vectors, concatenated vectors, and sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, reviews, labels, model, max_length=50, is_custom=True, feature_type='sequence'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            reviews: Pandas Series of review texts\n",
    "            labels: Numpy array of labels\n",
    "            model: Word2Vec model\n",
    "            max_length: Max sequence length (for CNN) or max words for concat (for FFNN)\n",
    "            is_custom: Whether using custom Word2Vec\n",
    "            feature_type: 'averaged', 'concatenated', or 'sequence'\n",
    "        \"\"\"\n",
    "        self.reviews = reviews.reset_index(drop=True)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.model = model\n",
    "        self.max_length = max_length\n",
    "        self.is_custom = is_custom\n",
    "        self.feature_type = feature_type\n",
    "        self.vector_size = model.wv.vector_size if is_custom else model.vector_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.feature_type == 'averaged':\n",
    "            feature = self._review_to_averaged(review)\n",
    "        elif self.feature_type == 'sequence':\n",
    "            feature = self._review_to_sequence(review)\n",
    "        else:  # concatenated\n",
    "            feature = self._review_to_concatenated(review)\n",
    "        \n",
    "        return torch.FloatTensor(feature), label\n",
    "    \n",
    "    def _review_to_averaged(self, review):\n",
    "        \"\"\"Generate averaged word vector (for simple models and Q4a)\"\"\"\n",
    "        words = review.split()\n",
    "        vectors = []\n",
    "        \n",
    "        for word in words:\n",
    "            try:\n",
    "                if self.is_custom:\n",
    "                    vec = self.model.wv[word].astype(np.float32)\n",
    "                else:\n",
    "                    vec = self.model[word].astype(np.float32)\n",
    "                vectors.append(vec)\n",
    "            except KeyError:\n",
    "                pass  # Skip OOV words\n",
    "        \n",
    "        if len(vectors) > 0:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(self.vector_size, dtype=np.float32)\n",
    "    \n",
    "    def _review_to_sequence(self, review):\n",
    "        \"\"\"Generate sequence of word vectors (for CNN)\"\"\"\n",
    "        words = review.split()[:self.max_length]\n",
    "        sequence = np.zeros((self.max_length, self.vector_size), dtype=np.float32)\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            try:\n",
    "                if self.is_custom:\n",
    "                    sequence[i] = self.model.wv[word].astype(np.float32)\n",
    "                else:\n",
    "                    sequence[i] = self.model[word].astype(np.float32)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        return sequence\n",
    "    \n",
    "    def _review_to_concatenated(self, review):\n",
    "        \"\"\"Generate concatenated word vectors (for FFNN)\"\"\"\n",
    "        words = review.split()[:self.max_length]\n",
    "        vectors = []\n",
    "        \n",
    "        for word in words:\n",
    "            try:\n",
    "                if self.is_custom:\n",
    "                    vec = self.model.wv[word].astype(np.float32)\n",
    "                else:\n",
    "                    vec = self.model[word].astype(np.float32)\n",
    "                vectors.append(vec)\n",
    "            except KeyError:\n",
    "                vectors.append(np.zeros(self.vector_size, dtype=np.float32))\n",
    "        \n",
    "        while len(vectors) < self.max_length:\n",
    "            vectors.append(np.zeros(self.vector_size, dtype=np.float32))\n",
    "        \n",
    "        return np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1636195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q3: PREPARING DATASETS (LAZY LOADING)\n",
      "============================================================\n",
      "Binary classification:\n",
      "  Train: 160,000 samples\n",
      "  Test: 40,000 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Q3: PREPARING DATASETS (LAZY LOADING)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Binary classification split\n",
    "df_binary = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "y_binary = df_binary['label'].values\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_reviews, x_test_reviews, y_train, y_test = train_test_split(\n",
    "    df_binary['review_body'], y_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Binary classification:\")\n",
    "print(f\"  Train: {len(x_train_reviews):,} samples\")\n",
    "print(f\"  Test: {len(x_test_reviews):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "608b3032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q3: PERCEPTRON + PRETRAINED\n",
      "============================================================\n",
      "Perceptron + Pretrained: 0.8043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q3: PERCEPTRON + PRETRAINED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create lazy dataset\n",
    "train_dataset_perc_pre = LazyReviewDataset(\n",
    "    x_train_reviews, y_train, pretrained_w2v,\n",
    "    is_custom=False, feature_type='averaged'\n",
    ")\n",
    "test_dataset_perc_pre = LazyReviewDataset(\n",
    "    x_test_reviews, y_test, pretrained_w2v,\n",
    "    is_custom=False, feature_type='averaged'\n",
    ")\n",
    "\n",
    "# Generate features in batches\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset_perc_pre, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_perc_pre, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Extract features for sklearn\n",
    "x_train_pre = []\n",
    "for batch_X, _ in train_loader:\n",
    "    x_train_pre.append(batch_X.numpy())\n",
    "x_train_pre = np.vstack(x_train_pre)\n",
    "\n",
    "x_test_pre = []\n",
    "for batch_X, _ in test_loader:\n",
    "    x_test_pre.append(batch_X.numpy())\n",
    "x_test_pre = np.vstack(x_test_pre)\n",
    "\n",
    "# Train Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "perc_pre = Perceptron(random_state=42, max_iter=1000)\n",
    "perc_pre.fit(x_train_pre, y_train)\n",
    "y_pred = perc_pre.predict(x_test_pre)\n",
    "acc_perc_pre = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Perceptron + Pretrained: {acc_perc_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del x_train_pre, x_test_pre, train_dataset_perc_pre, test_dataset_perc_pre\n",
    "del train_loader, test_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21557e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q3: PERCEPTRON + CUSTOM\n",
      "============================================================\n",
      "Perceptron + Custom: 0.8245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q3: PERCEPTRON + CUSTOM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_perc_cust = LazyReviewDataset(\n",
    "    x_train_reviews, y_train, custom_w2v,\n",
    "    is_custom=True, feature_type='averaged'\n",
    ")\n",
    "test_dataset_perc_cust = LazyReviewDataset(\n",
    "    x_test_reviews, y_test, custom_w2v,\n",
    "    is_custom=True, feature_type='averaged'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset_perc_cust, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_perc_cust, batch_size=1000, shuffle=False)\n",
    "\n",
    "x_train_cust = []\n",
    "for batch_X, _ in train_loader:\n",
    "    x_train_cust.append(batch_X.numpy())\n",
    "x_train_cust = np.vstack(x_train_cust)\n",
    "\n",
    "x_test_cust = []\n",
    "for batch_X, _ in test_loader:\n",
    "    x_test_cust.append(batch_X.numpy())\n",
    "x_test_cust = np.vstack(x_test_cust)\n",
    "\n",
    "perc_cust = Perceptron(random_state=42, max_iter=1000)\n",
    "perc_cust.fit(x_train_cust, y_train)\n",
    "y_pred = perc_cust.predict(x_test_cust)\n",
    "acc_perc_cust = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Perceptron + Custom: {acc_perc_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del x_train_cust, x_test_cust, train_dataset_perc_cust, test_dataset_perc_cust\n",
    "del train_loader, test_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71204954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q3: SVM + PRETRAINED\n",
      "============================================================\n",
      "Linear SVM + Pretrained: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q3: SVM + PRETRAINED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_svm_pre = LazyReviewDataset(\n",
    "    x_train_reviews, y_train, pretrained_w2v,\n",
    "    is_custom=False, feature_type='averaged'\n",
    ")\n",
    "test_dataset_svm_pre = LazyReviewDataset(\n",
    "    x_test_reviews, y_test, pretrained_w2v,\n",
    "    is_custom=False, feature_type='averaged'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset_svm_pre, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_svm_pre, batch_size=1000, shuffle=False)\n",
    "\n",
    "x_train_pre = []\n",
    "for batch_X, _ in train_loader:\n",
    "    x_train_pre.append(batch_X.numpy())\n",
    "x_train_pre = np.vstack(x_train_pre)\n",
    "\n",
    "x_test_pre = []\n",
    "for batch_X, _ in test_loader:\n",
    "    x_test_pre.append(batch_X.numpy())\n",
    "x_test_pre = np.vstack(x_test_pre)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_pre = LinearSVC(random_state=42, max_iter=1000)\n",
    "svm_pre.fit(x_train_pre, y_train)\n",
    "y_pred = svm_pre.predict(x_test_pre)\n",
    "acc_svm_pre = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Linear SVM + Pretrained: {acc_svm_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del x_train_pre, x_test_pre, train_dataset_svm_pre, test_dataset_svm_pre\n",
    "del train_loader, test_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3afae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q3: SVM + CUSTOM\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m test_loader = DataLoader(test_dataset_svm_cust, batch_size=\u001b[32m1000\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     17\u001b[39m x_train_cust = []\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_train_cust\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m x_train_cust = np.vstack(x_train_cust)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mLazyReviewDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# concatenated\u001b[39;00m\n\u001b[32m     36\u001b[39m     feature = \u001b[38;5;28mself\u001b[39m._review_to_concatenated(review)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m, label\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q3: SVM + CUSTOM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_svm_cust = LazyReviewDataset(\n",
    "    x_train_reviews, y_train, custom_w2v,\n",
    "    is_custom=True, feature_type='averaged'\n",
    ")\n",
    "test_dataset_svm_cust = LazyReviewDataset(\n",
    "    x_test_reviews, y_test, custom_w2v,\n",
    "    is_custom=True, feature_type='averaged'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset_svm_cust, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_svm_cust, batch_size=1000, shuffle=False)\n",
    "\n",
    "x_train_cust = []\n",
    "for batch_X, _ in train_loader:\n",
    "    x_train_cust.append(batch_X.numpy())\n",
    "x_train_cust = np.vstack(x_train_cust)\n",
    "\n",
    "x_test_cust = []\n",
    "for batch_X, _ in test_loader:\n",
    "\n",
    "    x_test_cust.append(batch_X.numpy())\n",
    "x_test_cust = np.vstack(x_test_cust)\n",
    "\n",
    "svm_cust = LinearSVC(random_state=42, max_iter=1000)\n",
    "svm_cust.fit(x_train_cust, y_train)\n",
    "y_pred = svm_cust.predict(x_test_cust)\n",
    "acc_svm_cust = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Linear SVM + Custom: {acc_svm_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del x_train_cust, x_test_cust, train_dataset_svm_cust, test_dataset_svm_cust\n",
    "del train_loader, test_loader\n",
    "del x_train_reviews, x_test_reviews, df_binary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                     Pretrained      Custom         \n",
      "-------------------------------------------------------\n",
      "Perceptron                0.6925          0.8176\n",
      "SVM                       0.8338          0.8617\n"
     ]
    }
   ],
   "source": [
    "results_q3 = {\n",
    "    'Perceptron_Pretrained': 0.6925,\n",
    "    'Perceptron_Custom': 0.8176,\n",
    "    'SVM_Pretrained': 0.8338,\n",
    "    'SVM_Custom': 0.8617\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Model':<25} {'Pretrained':<15} {'Custom':<15}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Perceptron':<25} {results_q3['Perceptron_Pretrained']:.4f}          {results_q3['Perceptron_Custom']:.4f}\")\n",
    "print(f\"{'SVM':<25} {results_q3['SVM_Pretrained']:.4f}          {results_q3['SVM_Custom']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a63b0",
   "metadata": {},
   "source": [
    "##### Key Findings<br>\n",
    "\n",
    "1. BEST MODEL: SVM with Custom Word2Vec = 86.17%\n",
    "\n",
    "2. CUSTOM >> PRETRAINED:\n",
    "   - Custom features outperform pretrained by 12.51% (Perceptron)\n",
    "   - Custom features outperform pretrained by 2.79% (SVM)\n",
    "   - Reason: Domain-specific training on office product reviews\n",
    "\n",
    "3. COMPARISON WITH HW1:\n",
    "   - HW1 best (Logistic + bigrams): 88.70%\n",
    "   - Q3 best (SVM + Word2Vec): 86.17%\n",
    "   - Difference: -2.53%\n",
    "\n",
    "4. CONCLUSION:\n",
    "   Averaged Word2Vec features perform well but slightly worse than\n",
    "   bigram features because:\n",
    "   - Averaging loses word order information\n",
    "   - Bigrams capture specific phrase patterns (e.g., \"not good\")\n",
    "   - Word2Vec captures semantic meaning but misses negation patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b7205",
   "metadata": {},
   "source": [
    "# Question 4: Feed Forward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463165c",
   "metadata": {},
   "source": [
    "(a) training a perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261012ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate = 0.5):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 50)  \n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.fc3 = nn.Linear(10, output_size)          \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f39031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Memory-efficient dataset that generates features on-the-fly.\n",
    "    Perfect for large datasets - only loads one batch at a time.\n",
    "    \"\"\"\n",
    "    def __init__(self, reviews, labels, model, max_length=50, is_custom=True, feature_type='sequence'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            reviews: Pandas Series of review texts\n",
    "            labels: Numpy array of labels\n",
    "            model: Word2Vec model\n",
    "            max_length: Max sequence length (for CNN) or max words for concat (for FFNN)\n",
    "            is_custom: Whether using custom Word2Vec\n",
    "            feature_type: 'sequence' for CNN, 'concatenated' for FFNN concat\n",
    "        \"\"\"\n",
    "        self.reviews = reviews.reset_index(drop=True)  # Reset index for clean access\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.model = model\n",
    "        self.max_length = max_length\n",
    "        self.is_custom = is_custom\n",
    "        self.feature_type = feature_type\n",
    "        self.vector_size = model.wv.vector_size if is_custom else model.vector_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.feature_type == 'sequence':\n",
    "            # Generate sequence for CNN (shape: max_length, vector_size)\n",
    "            feature = self._review_to_sequence(review)\n",
    "        else:  # concatenated\n",
    "            # Generate concatenated vector for FFNN (shape: max_length * vector_size)\n",
    "            feature = self._review_to_concatenated(review)\n",
    "        \n",
    "        return torch.FloatTensor(feature), label\n",
    "    \n",
    "    def _review_to_sequence(self, review):\n",
    "        \"\"\"Generate sequence of word vectors (for CNN)\"\"\"\n",
    "        words = review.split()[:self.max_length]\n",
    "        sequence = np.zeros((self.max_length, self.vector_size), dtype=np.float32)\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            try:\n",
    "                if self.is_custom:\n",
    "                    sequence[i] = self.model.wv[word].astype(np.float32)\n",
    "                else:\n",
    "                    sequence[i] = self.model[word].astype(np.float32)\n",
    "            except KeyError:\n",
    "                pass  # Keep as zeros for OOV\n",
    "        \n",
    "        return sequence\n",
    "    \n",
    "    def _review_to_concatenated(self, review):\n",
    "        \"\"\"Generate concatenated word vectors (for FFNN)\"\"\"\n",
    "        words = review.split()[:self.max_length]\n",
    "        vectors = []\n",
    "        \n",
    "        for word in words:\n",
    "            try:\n",
    "                if self.is_custom:\n",
    "                    vec = self.model.wv[word].astype(np.float32)\n",
    "                else:\n",
    "                    vec = self.model[word].astype(np.float32)\n",
    "                vectors.append(vec)\n",
    "            except KeyError:\n",
    "                vectors.append(np.zeros(self.vector_size, dtype=np.float32))\n",
    "        \n",
    "        # Pad to max_length\n",
    "        while len(vectors) < self.max_length:\n",
    "            vectors.append(np.zeros(self.vector_size, dtype=np.float32))\n",
    "        \n",
    "        return np.concatenate(vectors)  # Shape: (max_length * vector_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d277bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_binary = x_train_cust  \n",
    "x_test_binary = x_test_cust\n",
    "y_train_binary = y_train - 1\n",
    "y_test_binary = y_test - 1\n",
    "\n",
    "df_ternary = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "\n",
    "x_pretrained_ternary = np.vstack(df_ternary['pretrained_vec'])\n",
    "x_custom_ternary = np.vstack(df_ternary['custom_vec'])\n",
    "y_ternary = df_ternary['label'].values\n",
    "\n",
    "x_train_pre_ternary, x_test_pre_ternary, y_train_ternary, y_test_ternary = train_test_split(\n",
    "    x_pretrained_ternary, y_ternary, test_size=0.2, random_state=42\n",
    ")\n",
    "x_train_cust_ternary, x_test_cust_ternary, _, _ = train_test_split(\n",
    "    x_custom_ternary, y_ternary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train_ternary = y_train_ternary - 1\n",
    "y_test_ternary = y_test_ternary - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb81a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        running_train_loss = 0.0  \n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item() * features.size(0)\n",
    "            \n",
    "        avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item() * features.size(0)\n",
    "                                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_test_loss = running_test_loss / len(test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy, train_losses, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(a): FFNN AVERAGED - BINARY PRETRAINED\n",
      "============================================================\n",
      "\n",
      "Training FFNN Averaged - Binary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.4494, Test Loss: 0.3854, Test Accuracy: 0.8336\n",
      "Epoch [2/10], Train Loss: 0.4149, Test Loss: 0.3743, Test Accuracy: 0.8390\n",
      "Epoch [3/10], Train Loss: 0.4084, Test Loss: 0.3664, Test Accuracy: 0.8446\n",
      "Epoch [4/10], Train Loss: 0.4050, Test Loss: 0.3650, Test Accuracy: 0.8451\n",
      "Epoch [5/10], Train Loss: 0.3987, Test Loss: 0.3641, Test Accuracy: 0.8429\n",
      "Epoch [6/10], Train Loss: 0.3971, Test Loss: 0.3620, Test Accuracy: 0.8449\n",
      "Epoch [7/10], Train Loss: 0.3950, Test Loss: 0.3588, Test Accuracy: 0.8463\n",
      "Epoch [8/10], Train Loss: 0.3933, Test Loss: 0.3602, Test Accuracy: 0.8492\n",
      "Epoch [9/10], Train Loss: 0.3926, Test Loss: 0.3552, Test Accuracy: 0.8491\n",
      "Epoch [10/10], Train Loss: 0.3907, Test Loss: 0.3578, Test Accuracy: 0.8473\n",
      "\n",
      "FFNN Averaged - Binary Pretrained: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(a): FFNN AVERAGED - BINARY PRETRAINED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "train_indices, test_indices = train_test_split(range(len(df_binary)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_reviews = df_binary.iloc[train_indices]['review_body']\n",
    "test_reviews = df_binary.iloc[test_indices]['review_body']\n",
    "y_train = df_binary.iloc[train_indices]['label'].values - 1\n",
    "y_test = df_binary.iloc[test_indices]['label'].values - 1\n",
    "\n",
    "train_dataset = LazyReviewDataset(train_reviews, y_train, pretrained_w2v, is_custom=False, feature_type='averaged')\n",
    "test_dataset = LazyReviewDataset(test_reviews, y_test, pretrained_w2v, is_custom=False, feature_type='averaged')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FeedForwardNN(input_size=300, output_size=2, dropout_rate=0.5)\n",
    "acc_ffnn_avg_binary_pre, _, _, _ = train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "print(f\"\\nFFNN Averaged - Binary Pretrained: {acc_ffnn_avg_binary_pre:.4f}\")\n",
    "\n",
    "del train_dataset, test_dataset, train_loader, test_loader, df_binary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3557b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(a): FFNN AVERAGED - TERNARY PRETRAINED\n",
      "============================================================\n",
      "\n",
      "Training FFNN Averaged - Ternary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.8520, Test Loss: 0.7810, Test Accuracy: 0.6665\n",
      "Epoch [2/10], Train Loss: 0.8163, Test Loss: 0.7695, Test Accuracy: 0.6702\n",
      "Epoch [3/10], Train Loss: 0.8098, Test Loss: 0.7726, Test Accuracy: 0.6697\n",
      "Epoch [4/10], Train Loss: 0.8055, Test Loss: 0.7662, Test Accuracy: 0.6729\n",
      "Epoch [5/10], Train Loss: 0.8033, Test Loss: 0.7681, Test Accuracy: 0.6744\n",
      "Epoch [6/10], Train Loss: 0.8018, Test Loss: 0.7630, Test Accuracy: 0.6779\n",
      "Epoch [7/10], Train Loss: 0.7986, Test Loss: 0.7626, Test Accuracy: 0.6752\n",
      "Epoch [8/10], Train Loss: 0.7966, Test Loss: 0.7607, Test Accuracy: 0.6766\n",
      "Epoch [9/10], Train Loss: 0.7971, Test Loss: 0.7557, Test Accuracy: 0.6795\n",
      "Epoch [10/10], Train Loss: 0.7941, Test Loss: 0.7632, Test Accuracy: 0.6770\n",
      "\n",
      "FFNN Averaged - Ternary Pretrained: 0.6770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(a): FFNN AVERAGED - TERNARY PRETRAINED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "train_indices, test_indices = train_test_split(range(len(df_ternary)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_reviews = df_ternary.iloc[train_indices]['review_body']\n",
    "test_reviews = df_ternary.iloc[test_indices]['review_body']\n",
    "y_train = df_ternary.iloc[train_indices]['label'].values - 1\n",
    "y_test = df_ternary.iloc[test_indices]['label'].values - 1\n",
    "\n",
    "train_dataset = LazyReviewDataset(train_reviews, y_train, pretrained_w2v, is_custom=False, feature_type='averaged')\n",
    "test_dataset = LazyReviewDataset(test_reviews, y_test, pretrained_w2v, is_custom=False, feature_type='averaged')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FeedForwardNN(input_size=300, output_size=3, dropout_rate=0.5)\n",
    "acc_ffnn_avg_ternary_pre, _, _, _ = train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "print(f\"\\nFFNN Averaged - Ternary Pretrained: {acc_ffnn_avg_ternary_pre:.4f}\")\n",
    "\n",
    "del train_dataset, test_dataset, train_loader, test_loader, df_ternary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b6f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(a): FFNN AVERAGED - BINARY CUSTOM\n",
      "============================================================\n",
      "\n",
      "Training FFNN Averaged - Binary Custom...\n",
      "Epoch [1/10], Train Loss: 0.4001, Test Loss: 0.3305, Test Accuracy: 0.8650\n",
      "Epoch [2/10], Train Loss: 0.3671, Test Loss: 0.3243, Test Accuracy: 0.8629\n",
      "Epoch [3/10], Train Loss: 0.3605, Test Loss: 0.3181, Test Accuracy: 0.8687\n",
      "Epoch [4/10], Train Loss: 0.3546, Test Loss: 0.3182, Test Accuracy: 0.8688\n",
      "Epoch [5/10], Train Loss: 0.3526, Test Loss: 0.3142, Test Accuracy: 0.8711\n",
      "Epoch [6/10], Train Loss: 0.3522, Test Loss: 0.3134, Test Accuracy: 0.8703\n",
      "Epoch [7/10], Train Loss: 0.3496, Test Loss: 0.3109, Test Accuracy: 0.8733\n",
      "Epoch [8/10], Train Loss: 0.3478, Test Loss: 0.3111, Test Accuracy: 0.8727\n",
      "Epoch [9/10], Train Loss: 0.3472, Test Loss: 0.3081, Test Accuracy: 0.8731\n",
      "Epoch [10/10], Train Loss: 0.3452, Test Loss: 0.3081, Test Accuracy: 0.8733\n",
      "\n",
      "FFNN Averaged - Binary Custom: 0.8733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(a): FFNN AVERAGED - BINARY CUSTOM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "train_indices, test_indices = train_test_split(range(len(df_binary)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_reviews = df_binary.iloc[train_indices]['review_body']\n",
    "test_reviews = df_binary.iloc[test_indices]['review_body']\n",
    "y_train = df_binary.iloc[train_indices]['label'].values - 1\n",
    "y_test = df_binary.iloc[test_indices]['label'].values - 1\n",
    "\n",
    "train_dataset = LazyReviewDataset(train_reviews, y_train, custom_w2v, is_custom=True, feature_type='averaged')\n",
    "test_dataset = LazyReviewDataset(test_reviews, y_test, custom_w2v, is_custom=True, feature_type='averaged')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FeedForwardNN(input_size=300, output_size=2, dropout_rate=0.5)\n",
    "acc_ffnn_avg_binary_cust, train_loss_binary, test_loss_binary, test_acc_binary = train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "print(f\"\\nFFNN Averaged - Binary Custom: {acc_ffnn_avg_binary_cust:.4f}\")\n",
    "\n",
    "del train_dataset, test_dataset, train_loader, test_loader, df_binary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9418247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(a): FFNN AVERAGED - TERNARY CUSTOM\n",
      "============================================================\n",
      "\n",
      "Training FFNN Averaged - Ternary Custom...\n",
      "Epoch [1/10], Train Loss: 0.8046, Test Loss: 0.7247, Test Accuracy: 0.6913\n",
      "Epoch [2/10], Train Loss: 0.7752, Test Loss: 0.7203, Test Accuracy: 0.6932\n",
      "Epoch [3/10], Train Loss: 0.7692, Test Loss: 0.7148, Test Accuracy: 0.6961\n",
      "Epoch [4/10], Train Loss: 0.7639, Test Loss: 0.7123, Test Accuracy: 0.6959\n",
      "Epoch [5/10], Train Loss: 0.7630, Test Loss: 0.7112, Test Accuracy: 0.6952\n",
      "Epoch [6/10], Train Loss: 0.7601, Test Loss: 0.7081, Test Accuracy: 0.6976\n",
      "Epoch [7/10], Train Loss: 0.7578, Test Loss: 0.7072, Test Accuracy: 0.6976\n",
      "Epoch [8/10], Train Loss: 0.7587, Test Loss: 0.7046, Test Accuracy: 0.6987\n",
      "Epoch [9/10], Train Loss: 0.7569, Test Loss: 0.7071, Test Accuracy: 0.6977\n",
      "Epoch [10/10], Train Loss: 0.7550, Test Loss: 0.7082, Test Accuracy: 0.6974\n",
      "\n",
      "FFNN Averaged - Ternary Custom: 0.6974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(a): FFNN AVERAGED - TERNARY CUSTOM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "train_indices, test_indices = train_test_split(range(len(df_ternary)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_reviews = df_ternary.iloc[train_indices]['review_body']\n",
    "test_reviews = df_ternary.iloc[test_indices]['review_body']\n",
    "y_train = df_ternary.iloc[train_indices]['label'].values - 1\n",
    "y_test = df_ternary.iloc[test_indices]['label'].values - 1\n",
    "\n",
    "train_dataset = LazyReviewDataset(train_reviews, y_train, custom_w2v, is_custom=True, feature_type='averaged')\n",
    "test_dataset = LazyReviewDataset(test_reviews, y_test, custom_w2v, is_custom=True, feature_type='averaged')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FeedForwardNN(input_size=300, output_size=3, dropout_rate=0.5)\n",
    "acc_ffnn_avg_ternary_cust, train_loss_ternary, test_loss_ternary, test_acc_ternary = train_model(model, train_loader, test_loader, num_epochs=10)\n",
    "\n",
    "print(f\"\\nFFNN Averaged - Ternary Custom: {acc_ffnn_avg_ternary_cust:.4f}\")\n",
    "\n",
    "del train_dataset, test_dataset, train_loader, test_loader, df_ternary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dc62e",
   "metadata": {},
   "source": [
    "(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concatenated_word2vec(review, model, is_custom=False, max_words=10):\n",
    "    \"\"\"\n",
    "    Get concatenated Word2Vec vectors for first 10 words.\n",
    "    Pads with zeros if fewer than 10 words.\n",
    "    \n",
    "    Returns:\n",
    "        3000-dimensional vector (10 words Ã— 300 dims)\n",
    "    \"\"\"\n",
    "    words = review.split()[:max_words]\n",
    "    vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            if is_custom:\n",
    "                vec = model.wv[word]\n",
    "            else:\n",
    "                vec = model[word]\n",
    "            vectors.append(vec)\n",
    "        except KeyError:\n",
    "            vectors.append(np.zeros(model.vector_size))\n",
    "    \n",
    "    while len(vectors) < max_words:\n",
    "        vectors.append(np.zeros(model.vector_size))\n",
    "    \n",
    "    concatenated = np.concatenate(vectors)\n",
    "    return concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ace5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test review: purchase tab whim put movie poster use four inch t...\n",
      "Number of words: 31\n",
      "\n",
      "Concatenated vector shape: (3000,)\n",
      "Expected: (3000,)\n",
      "First 5 values: [-1.7382772 -0.6259943 -1.3400035 -1.5812477  1.1001413]\n"
     ]
    }
   ],
   "source": [
    "# Test concatenation function\n",
    "test_review = df_balanced['review_body'].iloc[0]\n",
    "print(f\"Test review: {test_review[:50]}...\")\n",
    "print(f\"Number of words: {len(test_review.split())}\")\n",
    "\n",
    "vec_concat = get_concatenated_word2vec(test_review, custom_w2v, is_custom=True)\n",
    "print(f\"\\nConcatenated vector shape: {vec_concat.shape}\")\n",
    "print(f\"Expected: (3000,)\")\n",
    "print(f\"First 5 values: {vec_concat[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2406d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - BINARY PRETRAINED - DATASET PREP\n",
      "============================================================\n",
      "Binary subset size: 200,000\n",
      "Train size: 160,000\n",
      "Test size: 40,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - BINARY PRETRAINED - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary_subset_pre = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "print(f\"Binary subset size: {len(df_binary_subset_pre):,}\")\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(df_binary_subset_pre)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_bin_pre = df_binary_subset_pre.iloc[train_indices]['review_body']\n",
    "test_reviews_bin_pre = df_binary_subset_pre.iloc[test_indices]['review_body']\n",
    "y_train_bin_pre = df_binary_subset_pre.iloc[train_indices]['label'].values - 1\n",
    "y_test_bin_pre = df_binary_subset_pre.iloc[test_indices]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices):,}\")\n",
    "print(f\"Test size: {len(test_indices):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_binary_subset_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d352e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - BINARY PRETRAINED - TRAINING\n",
      "============================================================\n",
      "Training FFNN Concatenated - Binary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.5184, Test Loss: 0.4612, Test Accuracy: 0.7815\n",
      "Epoch [2/10], Train Loss: 0.4803, Test Loss: 0.4463, Test Accuracy: 0.7900\n",
      "Epoch [3/10], Train Loss: 0.4655, Test Loss: 0.4403, Test Accuracy: 0.7914\n",
      "Epoch [4/10], Train Loss: 0.4532, Test Loss: 0.4366, Test Accuracy: 0.7939\n",
      "Epoch [5/10], Train Loss: 0.4457, Test Loss: 0.4342, Test Accuracy: 0.7954\n",
      "Epoch [6/10], Train Loss: 0.4366, Test Loss: 0.4346, Test Accuracy: 0.7948\n",
      "Epoch [7/10], Train Loss: 0.4296, Test Loss: 0.4362, Test Accuracy: 0.7962\n",
      "Epoch [8/10], Train Loss: 0.4224, Test Loss: 0.4343, Test Accuracy: 0.7961\n",
      "Epoch [9/10], Train Loss: 0.4142, Test Loss: 0.4368, Test Accuracy: 0.7966\n",
      "Epoch [10/10], Train Loss: 0.4072, Test Loss: 0.4390, Test Accuracy: 0.7958\n",
      "\n",
      "FFNN Concatenated - Binary Pretrained: 0.7958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - BINARY PRETRAINED - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_bin_concat_pre = LazyReviewDataset(\n",
    "    train_reviews_bin_pre, y_train_bin_pre, pretrained_w2v,\n",
    "    max_length=10, is_custom=False, feature_type='concatenated'\n",
    ")\n",
    "test_dataset_bin_concat_pre = LazyReviewDataset(\n",
    "    test_reviews_bin_pre, y_test_bin_pre, pretrained_w2v,\n",
    "    max_length=10, is_custom=False, feature_type='concatenated'\n",
    ")\n",
    "\n",
    "train_loader_bin_concat_pre = DataLoader(train_dataset_bin_concat_pre, batch_size=64, shuffle=True)\n",
    "test_loader_bin_concat_pre = DataLoader(test_dataset_bin_concat_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training FFNN Concatenated - Binary Pretrained...\")\n",
    "model_bin_concat_pre = FeedForwardNN(input_size=3000, output_size=2, dropout_rate=0.5)\n",
    "acc_ffnn_concat_binary_pre, _, _, _ = train_model(\n",
    "    model_bin_concat_pre, train_loader_bin_concat_pre, test_loader_bin_concat_pre, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nFFNN Concatenated - Binary Pretrained: {acc_ffnn_concat_binary_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_bin_pre, test_reviews_bin_pre, y_train_bin_pre, y_test_bin_pre\n",
    "del train_dataset_bin_concat_pre, test_dataset_bin_concat_pre\n",
    "del train_loader_bin_concat_pre, test_loader_bin_concat_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - TERNARY PRETRAINED - DATASET PREP\n",
      "============================================================\n",
      "Ternary subset size: 250,000\n",
      "Train size: 200,000\n",
      "Test size: 50,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - TERNARY PRETRAINED - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary_subset_pre = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "print(f\"Ternary subset size: {len(df_ternary_subset_pre):,}\")\n",
    "\n",
    "train_indices_ter_pre, test_indices_ter_pre = train_test_split(\n",
    "    range(len(df_ternary_subset_pre)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_ter_pre = df_ternary_subset_pre.iloc[train_indices_ter_pre]['review_body']\n",
    "test_reviews_ter_pre = df_ternary_subset_pre.iloc[test_indices_ter_pre]['review_body']\n",
    "y_train_ter_pre = df_ternary_subset_pre.iloc[train_indices_ter_pre]['label'].values - 1\n",
    "y_test_ter_pre = df_ternary_subset_pre.iloc[test_indices_ter_pre]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_ter_pre):,}\")\n",
    "print(f\"Test size: {len(test_indices_ter_pre):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_ternary_subset_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e626519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - TERNARY PRETRAINED - TRAINING\n",
      "============================================================\n",
      "Training FFNN Concatenated - Ternary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.9123, Test Loss: 0.8468, Test Accuracy: 0.6221\n",
      "Epoch [2/10], Train Loss: 0.8730, Test Loss: 0.8365, Test Accuracy: 0.6286\n",
      "Epoch [3/10], Train Loss: 0.8620, Test Loss: 0.8326, Test Accuracy: 0.6297\n",
      "Epoch [4/10], Train Loss: 0.8525, Test Loss: 0.8304, Test Accuracy: 0.6331\n",
      "Epoch [5/10], Train Loss: 0.8442, Test Loss: 0.8277, Test Accuracy: 0.6347\n",
      "Epoch [6/10], Train Loss: 0.8365, Test Loss: 0.8276, Test Accuracy: 0.6340\n",
      "Epoch [7/10], Train Loss: 0.8304, Test Loss: 0.8272, Test Accuracy: 0.6340\n",
      "Epoch [8/10], Train Loss: 0.8243, Test Loss: 0.8263, Test Accuracy: 0.6333\n",
      "Epoch [9/10], Train Loss: 0.8188, Test Loss: 0.8272, Test Accuracy: 0.6327\n",
      "Epoch [10/10], Train Loss: 0.8139, Test Loss: 0.8288, Test Accuracy: 0.6340\n",
      "\n",
      "FFNN Concatenated - Ternary Pretrained: 0.6340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - TERNARY PRETRAINED - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_ter_concat_pre = LazyReviewDataset(\n",
    "    train_reviews_ter_pre, y_train_ter_pre, pretrained_w2v,\n",
    "    max_length=10, is_custom=False, feature_type='concatenated'\n",
    ")\n",
    "test_dataset_ter_concat_pre = LazyReviewDataset(\n",
    "    test_reviews_ter_pre, y_test_ter_pre, pretrained_w2v,\n",
    "    max_length=10, is_custom=False, feature_type='concatenated'\n",
    ")\n",
    "\n",
    "train_loader_ter_concat_pre = DataLoader(train_dataset_ter_concat_pre, batch_size=64, shuffle=True)\n",
    "test_loader_ter_concat_pre = DataLoader(test_dataset_ter_concat_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training FFNN Concatenated - Ternary Pretrained...\")\n",
    "model_ter_concat_pre = FeedForwardNN(input_size=3000, output_size=3, dropout_rate=0.5)\n",
    "acc_ffnn_concat_ternary_pre, _, _, _ = train_model(\n",
    "    model_ter_concat_pre, train_loader_ter_concat_pre, test_loader_ter_concat_pre, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nFFNN Concatenated - Ternary Pretrained: {acc_ffnn_concat_ternary_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_ter_pre, test_reviews_ter_pre, y_train_ter_pre, y_test_ter_pre\n",
    "del train_dataset_ter_concat_pre, test_dataset_ter_concat_pre\n",
    "del train_loader_ter_concat_pre, test_loader_ter_concat_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19edf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - BINARY CUSTOM - DATASET PREP\n",
      "============================================================\n",
      "Binary subset size: 200,000\n",
      "Train size: 160,000\n",
      "Test size: 40,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - BINARY CUSTOM - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary_subset_cust = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "print(f\"Binary subset size: {len(df_binary_subset_cust):,}\")\n",
    "\n",
    "train_indices_bin_cust, test_indices_bin_cust = train_test_split(\n",
    "    range(len(df_binary_subset_cust)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_bin_cust = df_binary_subset_cust.iloc[train_indices_bin_cust]['review_body']\n",
    "test_reviews_bin_cust = df_binary_subset_cust.iloc[test_indices_bin_cust]['review_body']\n",
    "y_train_bin_cust = df_binary_subset_cust.iloc[train_indices_bin_cust]['label'].values - 1\n",
    "y_test_bin_cust = df_binary_subset_cust.iloc[test_indices_bin_cust]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_bin_cust):,}\")\n",
    "print(f\"Test size: {len(test_indices_bin_cust):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_binary_subset_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - BINARY CUSTOM - TRAINING\n",
      "============================================================\n",
      "Training FFNN Concatenated - Binary Custom...\n",
      "Epoch [1/10], Train Loss: 0.5045, Test Loss: 0.4354, Test Accuracy: 0.7927\n",
      "Epoch [2/10], Train Loss: 0.4633, Test Loss: 0.4255, Test Accuracy: 0.8034\n",
      "Epoch [3/10], Train Loss: 0.4504, Test Loss: 0.4199, Test Accuracy: 0.8059\n",
      "Epoch [4/10], Train Loss: 0.4382, Test Loss: 0.4173, Test Accuracy: 0.8072\n",
      "Epoch [5/10], Train Loss: 0.4301, Test Loss: 0.4151, Test Accuracy: 0.8096\n",
      "Epoch [6/10], Train Loss: 0.4215, Test Loss: 0.4130, Test Accuracy: 0.8081\n",
      "Epoch [7/10], Train Loss: 0.4143, Test Loss: 0.4125, Test Accuracy: 0.8110\n",
      "Epoch [8/10], Train Loss: 0.4068, Test Loss: 0.4144, Test Accuracy: 0.8115\n",
      "Epoch [9/10], Train Loss: 0.4027, Test Loss: 0.4138, Test Accuracy: 0.8089\n",
      "Epoch [10/10], Train Loss: 0.3982, Test Loss: 0.4146, Test Accuracy: 0.8105\n",
      "\n",
      "FFNN Concatenated - Binary Custom: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - BINARY CUSTOM - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_bin_concat_cust = LazyReviewDataset(\n",
    "    train_reviews_bin_cust, y_train_bin_cust, custom_w2v,\n",
    "    max_length=10, is_custom=True, feature_type='concatenated'\n",
    ")\n",
    "test_dataset_bin_concat_cust = LazyReviewDataset(\n",
    "    test_reviews_bin_cust, y_test_bin_cust, custom_w2v,\n",
    "    max_length=10, is_custom=True, feature_type='concatenated'\n",
    ")\n",
    "\n",
    "train_loader_bin_concat_cust = DataLoader(train_dataset_bin_concat_cust, batch_size=64, shuffle=True)\n",
    "test_loader_bin_concat_cust = DataLoader(test_dataset_bin_concat_cust, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training FFNN Concatenated - Binary Custom...\")\n",
    "model_bin_concat_cust = FeedForwardNN(input_size=3000, output_size=2, dropout_rate=0.5)\n",
    "acc_ffnn_concat_binary_cust, train_loss_bin_concat, test_loss_bin_concat, test_acc_bin_concat = train_model(\n",
    "    model_bin_concat_cust, train_loader_bin_concat_cust, test_loader_bin_concat_cust, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nFFNN Concatenated - Binary Custom: {acc_ffnn_concat_binary_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_bin_cust, test_reviews_bin_cust, y_train_bin_cust, y_test_bin_cust\n",
    "del train_dataset_bin_concat_cust, test_dataset_bin_concat_cust\n",
    "del train_loader_bin_concat_cust, test_loader_bin_concat_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f03c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - TERNARY CUSTOM - DATASET PREP\n",
      "============================================================\n",
      "Ternary subset size: 250,000\n",
      "Train size: 200,000\n",
      "Test size: 50,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - TERNARY CUSTOM - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary_subset_cust = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "print(f\"Ternary subset size: {len(df_ternary_subset_cust):,}\")\n",
    "\n",
    "train_indices_ter_cust, test_indices_ter_cust = train_test_split(\n",
    "    range(len(df_ternary_subset_cust)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_ter_cust = df_ternary_subset_cust.iloc[train_indices_ter_cust]['review_body']\n",
    "test_reviews_ter_cust = df_ternary_subset_cust.iloc[test_indices_ter_cust]['review_body']\n",
    "y_train_ter_cust = df_ternary_subset_cust.iloc[train_indices_ter_cust]['label'].values - 1\n",
    "y_test_ter_cust = df_ternary_subset_cust.iloc[test_indices_ter_cust]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_ter_cust):,}\")\n",
    "print(f\"Test size: {len(test_indices_ter_cust):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_ternary_subset_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q4(b): FFNN CONCATENATED - TERNARY CUSTOM - TRAINING\n",
      "============================================================\n",
      "Training FFNN Concatenated - Ternary Custom...\n",
      "Epoch [1/10], Train Loss: 0.8982, Test Loss: 0.8315, Test Accuracy: 0.6343\n",
      "Epoch [2/10], Train Loss: 0.8596, Test Loss: 0.8255, Test Accuracy: 0.6389\n",
      "Epoch [3/10], Train Loss: 0.8458, Test Loss: 0.8172, Test Accuracy: 0.6413\n",
      "Epoch [4/10], Train Loss: 0.8380, Test Loss: 0.8165, Test Accuracy: 0.6438\n",
      "Epoch [5/10], Train Loss: 0.8300, Test Loss: 0.8140, Test Accuracy: 0.6418\n",
      "Epoch [6/10], Train Loss: 0.8235, Test Loss: 0.8180, Test Accuracy: 0.6443\n",
      "Epoch [7/10], Train Loss: 0.8166, Test Loss: 0.8128, Test Accuracy: 0.6459\n",
      "Epoch [8/10], Train Loss: 0.8120, Test Loss: 0.8131, Test Accuracy: 0.6467\n",
      "Epoch [9/10], Train Loss: 0.8062, Test Loss: 0.8140, Test Accuracy: 0.6462\n",
      "Epoch [10/10], Train Loss: 0.8050, Test Loss: 0.8134, Test Accuracy: 0.6461\n",
      "\n",
      "FFNN Concatenated - Ternary Custom: 0.6461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q4(b): FFNN CONCATENATED - TERNARY CUSTOM - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_ter_concat_cust = LazyReviewDataset(\n",
    "    train_reviews_ter_cust, y_train_ter_cust, custom_w2v,\n",
    "    max_length=10, is_custom=True, feature_type='concatenated'\n",
    ")\n",
    "test_dataset_ter_concat_cust = LazyReviewDataset(\n",
    "    test_reviews_ter_cust, y_test_ter_cust, custom_w2v,\n",
    "    max_length=10, is_custom=True, feature_type='concatenated'\n",
    ")\n",
    "\n",
    "train_loader_ter_concat_cust = DataLoader(train_dataset_ter_concat_cust, batch_size=64, shuffle=True)\n",
    "test_loader_ter_concat_cust = DataLoader(test_dataset_ter_concat_cust, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training FFNN Concatenated - Ternary Custom...\")\n",
    "model_ter_concat_cust = FeedForwardNN(input_size=3000, output_size=3, dropout_rate=0.5)\n",
    "acc_ffnn_concat_ternary_cust, train_loss_ter_concat, test_loss_ter_concat, test_acc_ter_concat = train_model(\n",
    "    model_ter_concat_cust, train_loader_ter_concat_cust, test_loader_ter_concat_cust, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nFFNN Concatenated - Ternary Custom: {acc_ffnn_concat_ternary_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_ter_cust, test_reviews_ter_cust, y_train_ter_cust, y_test_ter_cust\n",
    "del train_dataset_ter_concat_cust, test_dataset_ter_concat_cust\n",
    "del train_loader_ter_concat_cust, test_loader_ter_concat_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d556c",
   "metadata": {},
   "source": [
    "Q4 FINAL COMPARISON: AVERAGED vs CONCATENATED\n",
    "\n",
    "|Classification   |    Q4(a) Averaged   |    Q4(b) Concatenated  |  Difference|     \n",
    "|-----------------|---------------------|------------------------|------------|\n",
    "|Binary           |   0.8728            |  0.8108                | -6.20%     |\n",
    "|Ternary          |   0.6974            |  0.6473                | -5.01%     |\n",
    "\n",
    "\n",
    "CONCLUSION:\n",
    "\n",
    "AVERAGED VECTORS (Q4a) outperform CONCATENATED VECTORS (Q4b):\n",
    "\n",
    "Binary:  87.28% vs 81.08% (+6.20% for averaged)<br>\n",
    "Ternary: 69.74% vs 64.73% (+5.01% for averaged)\n",
    "\n",
    "REASONS:\n",
    "1. Averaged uses ALL words â†’ more complete sentiment representation\n",
    "2. Concatenated uses only FIRST 10 words â†’ loses information\n",
    "3. Lower dimensionality (300 vs 3000) â†’ less overfitting\n",
    "4. Even with dropout, concatenated features couldn't overcome these issues\n",
    "\n",
    "BEST OVERALL: Q4(a) with Averaged Vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617f6ca",
   "metadata": {},
   "source": [
    "# Q5 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_to_sequences(reviews, model, max_length=50, is_custom=True):\n",
    "    \"\"\"\n",
    "    Memory-efficient: Convert reviews to sequences using float32.\n",
    "    \n",
    "    Args:\n",
    "        reviews: List or Series of review strings\n",
    "        model: Word2Vec model\n",
    "        max_length: Maximum sequence length (default 50)\n",
    "        is_custom: Whether using custom Word2Vec\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (num_reviews, max_length, 300) with dtype float32\n",
    "    \"\"\"\n",
    "    vector_size = model.wv.vector_size if is_custom else model.vector_size\n",
    "    num_reviews = len(reviews)\n",
    "    \n",
    "    # Pre-allocate array with FLOAT32 (saves 50% memory!)\n",
    "    sequences = np.zeros((num_reviews, max_length, vector_size), dtype=np.float32)\n",
    "    \n",
    "    print(f\"Generating sequences for {num_reviews:,} reviews...\")\n",
    "    \n",
    "    for idx, review in enumerate(reviews):\n",
    "        words = review.split()[:max_length]\n",
    "        \n",
    "        # Fill in word vectors\n",
    "        for word_idx, word in enumerate(words):\n",
    "            try:\n",
    "                if is_custom:\n",
    "                    vec = model.wv[word]\n",
    "                else:\n",
    "                    vec = model[word]\n",
    "                sequences[idx, word_idx] = vec.astype(np.float32)\n",
    "            except KeyError:\n",
    "                # OOV word - already zeros, skip\n",
    "                pass\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd3906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimized sequence generation...\n",
      "Generating sequences for 1 reviews...\n",
      "Sequence shape: (1, 50, 300)\n",
      "Data type: float32\n",
      "Memory used: 0.06 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing optimized sequence generation...\")\n",
    "test_review = df_balanced['review_body'].iloc[0]\n",
    "test_seq = reviews_to_sequences([test_review], custom_w2v, max_length=50, is_custom=True)\n",
    "print(f\"Sequence shape: {test_seq.shape}\")\n",
    "print(f\"Data type: {test_seq.dtype}\")  # Should show float32\n",
    "print(f\"Memory used: {test_seq.nbytes / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ee547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embed_dim=300, num_classes=2, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        2-layer CNN for text classification\n",
    "        \n",
    "        Args:\n",
    "            embed_dim: Word vector dimension (300 for Word2Vec)\n",
    "            num_classes: Number of output classes (2 for binary, 3 for ternary)\n",
    "            dropout_rate: Dropout rate for regularization\n",
    "        \"\"\"\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        # Conv layers\n",
    "        # Input: (batch, seq_len, embed_dim) â†’ need to transpose to (batch, embed_dim, seq_len) for Conv1d\n",
    "        self.conv1 = nn.Conv1d(in_channels=embed_dim, out_channels=50, kernel_size=4, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=50, out_channels=10, kernel_size=4, padding=1)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)  # Pool to fixed size\n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc = nn.Linear(10, num_classes)\n",
    "        \n",
    "        # Activation & regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, embed_dim) = (batch, 50, 300)\n",
    "        \n",
    "        # Transpose for Conv1d: (batch, embed_dim, seq_len) = (batch, 300, 50)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Conv layer 1\n",
    "        x = self.conv1(x)        # (batch, 50, seq_len)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Conv layer 2\n",
    "        x = self.conv2(x)        # (batch, 10, seq_len)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = self.pool(x)         # (batch, 10, 1)\n",
    "        x = x.squeeze(2)         # (batch, 10)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = self.fc(x)           # (batch, num_classes)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNReviewDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        \"\"\"\n",
    "        Dataset for CNN that handles sequences\n",
    "        \n",
    "        Args:\n",
    "            sequences: numpy array of shape (num_samples, max_length, embed_dim)\n",
    "            labels: numpy array of labels\n",
    "        \"\"\"\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47136919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - BINARY PRETRAINED - DATASET PREP\n",
      "============================================================\n",
      "Binary subset size: 200,000\n",
      "Train size: 160,000\n",
      "Test size: 40,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - BINARY PRETRAINED - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary_cnn_pre = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "print(f\"Binary subset size: {len(df_binary_cnn_pre):,}\")\n",
    "\n",
    "train_indices_cnn_bin_pre, test_indices_cnn_bin_pre = train_test_split(\n",
    "    range(len(df_binary_cnn_pre)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_cnn_bin_pre = df_binary_cnn_pre.iloc[train_indices_cnn_bin_pre]['review_body']\n",
    "test_reviews_cnn_bin_pre = df_binary_cnn_pre.iloc[test_indices_cnn_bin_pre]['review_body']\n",
    "y_train_cnn_bin_pre = df_binary_cnn_pre.iloc[train_indices_cnn_bin_pre]['label'].values - 1\n",
    "y_test_cnn_bin_pre = df_binary_cnn_pre.iloc[test_indices_cnn_bin_pre]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_cnn_bin_pre):,}\")\n",
    "print(f\"Test size: {len(test_indices_cnn_bin_pre):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_binary_cnn_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cc3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - BINARY PRETRAINED - TRAINING\n",
      "============================================================\n",
      "ðŸš€ Training CNN - Binary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.3903, Test Loss: 0.3705, Test Accuracy: 0.8609\n",
      "Epoch [2/10], Train Loss: 0.3332, Test Loss: 0.3620, Test Accuracy: 0.8648\n",
      "Epoch [3/10], Train Loss: 0.3184, Test Loss: 0.3583, Test Accuracy: 0.8653\n",
      "Epoch [4/10], Train Loss: 0.3080, Test Loss: 0.3478, Test Accuracy: 0.8663\n",
      "Epoch [5/10], Train Loss: 0.3004, Test Loss: 0.3402, Test Accuracy: 0.8769\n",
      "Epoch [6/10], Train Loss: 0.2960, Test Loss: 0.3307, Test Accuracy: 0.8817\n",
      "Epoch [7/10], Train Loss: 0.2920, Test Loss: 0.3275, Test Accuracy: 0.8796\n",
      "Epoch [8/10], Train Loss: 0.2858, Test Loss: 0.3327, Test Accuracy: 0.8747\n",
      "Epoch [9/10], Train Loss: 0.2821, Test Loss: 0.3218, Test Accuracy: 0.8814\n",
      "Epoch [10/10], Train Loss: 0.2786, Test Loss: 0.3233, Test Accuracy: 0.8834\n",
      "\n",
      "CNN - Binary Pretrained: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - BINARY PRETRAINED - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_cnn_bin_pre = LazyReviewDataset(\n",
    "    train_reviews_cnn_bin_pre, y_train_cnn_bin_pre, pretrained_w2v,\n",
    "    max_length=50, is_custom=False, feature_type='sequence'\n",
    ")\n",
    "test_dataset_cnn_bin_pre = LazyReviewDataset(\n",
    "    test_reviews_cnn_bin_pre, y_test_cnn_bin_pre, pretrained_w2v,\n",
    "    max_length=50, is_custom=False, feature_type='sequence'\n",
    ")\n",
    "\n",
    "train_loader_cnn_bin_pre = DataLoader(train_dataset_cnn_bin_pre, batch_size=64, shuffle=True)\n",
    "test_loader_cnn_bin_pre = DataLoader(test_dataset_cnn_bin_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"ðŸš€ Training CNN - Binary Pretrained...\")\n",
    "model_cnn_binary_pre = TextCNN(embed_dim=300, num_classes=2, dropout_rate=0.5)\n",
    "acc_cnn_binary_pre, _, _, _ = train_model(\n",
    "    model_cnn_binary_pre, train_loader_cnn_bin_pre, test_loader_cnn_bin_pre, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nCNN - Binary Pretrained: {acc_cnn_binary_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_cnn_bin_pre, test_reviews_cnn_bin_pre, y_train_cnn_bin_pre, y_test_cnn_bin_pre\n",
    "del train_dataset_cnn_bin_pre, test_dataset_cnn_bin_pre\n",
    "del train_loader_cnn_bin_pre, test_loader_cnn_bin_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - TERNARY PRETRAINED - DATASET PREP\n",
      "============================================================\n",
      "Ternary subset size: 250,000\n",
      "Train size: 200,000\n",
      "Test size: 50,000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - TERNARY PRETRAINED - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary_cnn_pre = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "print(f\"Ternary subset size: {len(df_ternary_cnn_pre):,}\")\n",
    "\n",
    "train_indices_cnn_ter_pre, test_indices_cnn_ter_pre = train_test_split(\n",
    "    range(len(df_ternary_cnn_pre)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_cnn_ter_pre = df_ternary_cnn_pre.iloc[train_indices_cnn_ter_pre]['review_body']\n",
    "test_reviews_cnn_ter_pre = df_ternary_cnn_pre.iloc[test_indices_cnn_ter_pre]['review_body']\n",
    "y_train_cnn_ter_pre = df_ternary_cnn_pre.iloc[train_indices_cnn_ter_pre]['label'].values - 1\n",
    "y_test_cnn_ter_pre = df_ternary_cnn_pre.iloc[test_indices_cnn_ter_pre]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_cnn_ter_pre):,}\")\n",
    "print(f\"Test size: {len(test_indices_cnn_ter_pre):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_ternary_cnn_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e368e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - TERNARY PRETRAINED - TRAINING\n",
      "============================================================\n",
      "Training CNN - Ternary Pretrained...\n",
      "Epoch [1/10], Train Loss: 0.7760, Test Loss: 0.7714, Test Accuracy: 0.6996\n",
      "Epoch [2/10], Train Loss: 0.7254, Test Loss: 0.7586, Test Accuracy: 0.6993\n",
      "Epoch [3/10], Train Loss: 0.7095, Test Loss: 0.7397, Test Accuracy: 0.7079\n",
      "Epoch [4/10], Train Loss: 0.6998, Test Loss: 0.7388, Test Accuracy: 0.7086\n",
      "Epoch [5/10], Train Loss: 0.6928, Test Loss: 0.7433, Test Accuracy: 0.7124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining CNN - Ternary Pretrained...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m model_cnn_ternary_pre = TextCNN(embed_dim=\u001b[32m300\u001b[39m, num_classes=\u001b[32m3\u001b[39m, dropout_rate=\u001b[32m0.5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m acc_cnn_ternary_pre, _, _, _ = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_cnn_ternary_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_cnn_ter_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_cnn_ter_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCNN - Ternary Pretrained: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_cnn_ternary_pre\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, num_epochs)\u001b[39m\n\u001b[32m     21\u001b[39m outputs = model(features)\n\u001b[32m     22\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m optimizer.step()\n\u001b[32m     26\u001b[39m running_train_loss += loss.item() * features.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\omgha\\OneDrive\\Documents\\GitHub\\CSCI-544-Assignment\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - TERNARY PRETRAINED - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_cnn_ter_pre = LazyReviewDataset(\n",
    "    train_reviews_cnn_ter_pre, y_train_cnn_ter_pre, pretrained_w2v,\n",
    "    max_length=50, is_custom=False, feature_type='sequence'\n",
    ")\n",
    "test_dataset_cnn_ter_pre = LazyReviewDataset(\n",
    "    test_reviews_cnn_ter_pre, y_test_cnn_ter_pre, pretrained_w2v,\n",
    "    max_length=50, is_custom=False, feature_type='sequence'\n",
    ")\n",
    "\n",
    "train_loader_cnn_ter_pre = DataLoader(train_dataset_cnn_ter_pre, batch_size=64, shuffle=True)\n",
    "test_loader_cnn_ter_pre = DataLoader(test_dataset_cnn_ter_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training CNN - Ternary Pretrained...\")\n",
    "model_cnn_ternary_pre = TextCNN(embed_dim=300, num_classes=3, dropout_rate=0.5)\n",
    "acc_cnn_ternary_pre, _, _, _ = train_model(\n",
    "    model_cnn_ternary_pre, train_loader_cnn_ter_pre, test_loader_cnn_ter_pre, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nCNN - Ternary Pretrained: {acc_cnn_ternary_pre:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_cnn_ter_pre, test_reviews_cnn_ter_pre, y_train_cnn_ter_pre, y_test_cnn_ter_pre\n",
    "del train_dataset_cnn_ter_pre, test_dataset_cnn_ter_pre\n",
    "del train_loader_cnn_ter_pre, test_loader_cnn_ter_pre\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q5: CNN - BINARY WITH CUSTOM EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "1. Generating TRAIN sequences...\n",
      "Generating sequences for 160,000 reviews...\n",
      "  Processed 10000/160,000 reviews...\n",
      "  Processed 20000/160,000 reviews...\n",
      "  Processed 30000/160,000 reviews...\n",
      "  Processed 40000/160,000 reviews...\n",
      "  Processed 50000/160,000 reviews...\n",
      "  Processed 60000/160,000 reviews...\n",
      "  Processed 70000/160,000 reviews...\n",
      "  Processed 80000/160,000 reviews...\n",
      "  Processed 90000/160,000 reviews...\n",
      "  Processed 100000/160,000 reviews...\n",
      "  Processed 110000/160,000 reviews...\n",
      "  Processed 120000/160,000 reviews...\n",
      "  Processed 130000/160,000 reviews...\n",
      "  Processed 140000/160,000 reviews...\n",
      "  Processed 150000/160,000 reviews...\n",
      "  Processed 160000/160,000 reviews...\n",
      "\n",
      "2. Generating TEST sequences...\n",
      "Generating sequences for 40,000 reviews...\n",
      "  Processed 10000/40,000 reviews...\n",
      "  Processed 20000/40,000 reviews...\n",
      "  Processed 30000/40,000 reviews...\n",
      "  Processed 40000/40,000 reviews...\n",
      "\n",
      "Features ready: Train (160000, 50, 300), Test (40000, 50, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - BINARY CUSTOM - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_binary_cnn_cust = df_balanced[df_balanced['label'].isin([1, 2])].copy()\n",
    "print(f\"Binary subset size: {len(df_binary_cnn_cust):,}\")\n",
    "\n",
    "train_indices_cnn_bin_cust, test_indices_cnn_bin_cust = train_test_split(\n",
    "    range(len(df_binary_cnn_cust)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_cnn_bin_cust = df_binary_cnn_cust.iloc[train_indices_cnn_bin_cust]['review_body']\n",
    "test_reviews_cnn_bin_cust = df_binary_cnn_cust.iloc[test_indices_cnn_bin_cust]['review_body']\n",
    "y_train_cnn_bin_cust = df_binary_cnn_cust.iloc[train_indices_cnn_bin_cust]['label'].values - 1\n",
    "y_test_cnn_bin_cust = df_binary_cnn_cust.iloc[test_indices_cnn_bin_cust]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_cnn_bin_cust):,}\")\n",
    "print(f\"Test size: {len(test_indices_cnn_bin_cust):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_binary_cnn_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - BINARY CUSTOM\n",
      "============================================================\n",
      "\n",
      "Training CNN - Binary Custom...\n",
      "Epoch [1/10], Train Loss: 0.3714, Test Loss: 0.3748, Test Accuracy: 0.8692\n",
      "Epoch [2/10], Train Loss: 0.3287, Test Loss: 0.3552, Test Accuracy: 0.8739\n",
      "Epoch [3/10], Train Loss: 0.3187, Test Loss: 0.3485, Test Accuracy: 0.8677\n",
      "Epoch [4/10], Train Loss: 0.3103, Test Loss: 0.3514, Test Accuracy: 0.8731\n",
      "Epoch [5/10], Train Loss: 0.3050, Test Loss: 0.3447, Test Accuracy: 0.8682\n",
      "Epoch [6/10], Train Loss: 0.2992, Test Loss: 0.3346, Test Accuracy: 0.8749\n",
      "Epoch [7/10], Train Loss: 0.2963, Test Loss: 0.3556, Test Accuracy: 0.8598\n",
      "Epoch [8/10], Train Loss: 0.2943, Test Loss: 0.3253, Test Accuracy: 0.8831\n",
      "Epoch [9/10], Train Loss: 0.2916, Test Loss: 0.3536, Test Accuracy: 0.8752\n",
      "Epoch [10/10], Train Loss: 0.2897, Test Loss: 0.3370, Test Accuracy: 0.8672\n",
      "\n",
      "CNN - Binary Custom: 0.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - BINARY CUSTOM - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_cnn_bin_cust = LazyReviewDataset(\n",
    "    train_reviews_cnn_bin_cust, y_train_cnn_bin_cust, custom_w2v,\n",
    "    max_length=50, is_custom=True, feature_type='sequence'\n",
    ")\n",
    "test_dataset_cnn_bin_cust = LazyReviewDataset(\n",
    "    test_reviews_cnn_bin_cust, y_test_cnn_bin_cust, custom_w2v,\n",
    "    max_length=50, is_custom=True, feature_type='sequence'\n",
    ")\n",
    "\n",
    "train_loader_cnn_bin_cust = DataLoader(train_dataset_cnn_bin_cust, batch_size=64, shuffle=True)\n",
    "test_loader_cnn_bin_cust = DataLoader(test_dataset_cnn_bin_cust, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training CNN - Binary Custom...\")\n",
    "model_cnn_binary_cust = TextCNN(embed_dim=300, num_classes=2, dropout_rate=0.5)\n",
    "acc_cnn_binary_cust, train_loss_cnn_bin, test_loss_cnn_bin, test_acc_cnn_bin = train_model(\n",
    "    model_cnn_binary_cust, train_loader_cnn_bin_cust, test_loader_cnn_bin_cust, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nCNN - Binary Custom: {acc_cnn_binary_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_cnn_bin_cust, test_reviews_cnn_bin_cust, y_train_cnn_bin_cust, y_test_cnn_bin_cust\n",
    "del train_dataset_cnn_bin_cust, test_dataset_cnn_bin_cust\n",
    "del train_loader_cnn_bin_cust, test_loader_cnn_bin_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f47fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - TERNARY WITH CUSTOM EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "1. Generating TRAIN sequences...\n",
      "Generating sequences for 200,000 reviews...\n",
      "  Processed 10000/200,000 reviews...\n",
      "  Processed 20000/200,000 reviews...\n",
      "  Processed 30000/200,000 reviews...\n",
      "  Processed 40000/200,000 reviews...\n",
      "  Processed 50000/200,000 reviews...\n",
      "  Processed 60000/200,000 reviews...\n",
      "  Processed 70000/200,000 reviews...\n",
      "  Processed 80000/200,000 reviews...\n",
      "  Processed 90000/200,000 reviews...\n",
      "  Processed 100000/200,000 reviews...\n",
      "  Processed 110000/200,000 reviews...\n",
      "  Processed 120000/200,000 reviews...\n",
      "  Processed 130000/200,000 reviews...\n",
      "  Processed 140000/200,000 reviews...\n",
      "  Processed 150000/200,000 reviews...\n",
      "  Processed 160000/200,000 reviews...\n",
      "  Processed 170000/200,000 reviews...\n",
      "  Processed 180000/200,000 reviews...\n",
      "  Processed 190000/200,000 reviews...\n",
      "  Processed 200000/200,000 reviews...\n",
      "\n",
      "2. Generating TEST sequences...\n",
      "Generating sequences for 50,000 reviews...\n",
      "  Processed 10000/50,000 reviews...\n",
      "  Processed 20000/50,000 reviews...\n",
      "  Processed 30000/50,000 reviews...\n",
      "  Processed 40000/50,000 reviews...\n",
      "  Processed 50000/50,000 reviews...\n",
      "\n",
      "Features ready: Train (200000, 50, 300), Test (50000, 50, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - TERNARY CUSTOM - DATASET PREP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_ternary_cnn_cust = df_balanced[df_balanced['label'].isin([1, 2, 3])].copy()\n",
    "print(f\"Ternary subset size: {len(df_ternary_cnn_cust):,}\")\n",
    "\n",
    "train_indices_cnn_ter_cust, test_indices_cnn_ter_cust = train_test_split(\n",
    "    range(len(df_ternary_cnn_cust)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_reviews_cnn_ter_cust = df_ternary_cnn_cust.iloc[train_indices_cnn_ter_cust]['review_body']\n",
    "test_reviews_cnn_ter_cust = df_ternary_cnn_cust.iloc[test_indices_cnn_ter_cust]['review_body']\n",
    "y_train_cnn_ter_cust = df_ternary_cnn_cust.iloc[train_indices_cnn_ter_cust]['label'].values - 1\n",
    "y_test_cnn_ter_cust = df_ternary_cnn_cust.iloc[test_indices_cnn_ter_cust]['label'].values - 1\n",
    "\n",
    "print(f\"Train size: {len(train_indices_cnn_ter_cust):,}\")\n",
    "print(f\"Test size: {len(test_indices_cnn_ter_cust):,}\")\n",
    "\n",
    "# Clean up\n",
    "del df_ternary_cnn_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Q5: CNN - TERNARY CUSTOM\n",
      "============================================================\n",
      "\n",
      "Training CNN - Ternary Custom...\n",
      "Epoch [1/10], Train Loss: 0.7641, Test Loss: 0.7587, Test Accuracy: 0.6951\n",
      "Epoch [2/10], Train Loss: 0.7202, Test Loss: 0.7564, Test Accuracy: 0.6937\n",
      "Epoch [3/10], Train Loss: 0.7067, Test Loss: 0.7458, Test Accuracy: 0.7056\n",
      "Epoch [4/10], Train Loss: 0.6991, Test Loss: 0.7502, Test Accuracy: 0.7017\n",
      "Epoch [5/10], Train Loss: 0.6942, Test Loss: 0.7325, Test Accuracy: 0.7072\n",
      "Epoch [6/10], Train Loss: 0.6917, Test Loss: 0.7253, Test Accuracy: 0.7053\n",
      "Epoch [7/10], Train Loss: 0.6878, Test Loss: 0.7371, Test Accuracy: 0.7041\n",
      "Epoch [8/10], Train Loss: 0.6835, Test Loss: 0.7300, Test Accuracy: 0.7110\n",
      "Epoch [9/10], Train Loss: 0.6808, Test Loss: 0.7298, Test Accuracy: 0.7053\n",
      "Epoch [10/10], Train Loss: 0.6792, Test Loss: 0.7197, Test Accuracy: 0.7097\n",
      "\n",
      "CNN - Ternary Custom: 0.7097\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Q5: CNN - TERNARY CUSTOM - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_dataset_cnn_ter_cust = LazyReviewDataset(\n",
    "    train_reviews_cnn_ter_cust, y_train_cnn_ter_cust, custom_w2v,\n",
    "    max_length=50, is_custom=True, feature_type='sequence'\n",
    ")\n",
    "test_dataset_cnn_ter_cust = LazyReviewDataset(\n",
    "    test_reviews_cnn_ter_cust, y_test_cnn_ter_cust, custom_w2v,\n",
    "    max_length=50, is_custom=True, feature_type='sequence'\n",
    ")\n",
    "\n",
    "train_loader_cnn_ter_cust = DataLoader(train_dataset_cnn_ter_cust, batch_size=64, shuffle=True)\n",
    "test_loader_cnn_ter_cust = DataLoader(test_dataset_cnn_ter_cust, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training CNN - Ternary Custom...\")\n",
    "model_cnn_ternary_cust = TextCNN(embed_dim=300, num_classes=3, dropout_rate=0.5)\n",
    "acc_cnn_ternary_cust, train_loss_cnn_ter, test_loss_cnn_ter, test_acc_cnn_ter = train_model(\n",
    "    model_cnn_ternary_cust, train_loader_cnn_ter_cust, test_loader_cnn_ter_cust, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nCNN - Ternary Custom: {acc_cnn_ternary_cust:.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del train_reviews_cnn_ter_cust, test_reviews_cnn_ter_cust, y_train_cnn_ter_cust, y_test_cnn_ter_cust\n",
    "del train_dataset_cnn_ter_cust, test_dataset_cnn_ter_cust\n",
    "del train_loader_cnn_ter_cust, test_loader_cnn_ter_cust\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "HOMEWORK 2 - COMPLETE 16 ACCURACY VALUES\n",
      "===========================================================================\n",
      "\n",
      "ðŸ“Š Q3: SIMPLE MODELS (4 values)\n",
      "---------------------------------------------------------------------------\n",
      "Model                          Pretrained             Custom                \n",
      "Perceptron                     0.6925                 0.8153                \n",
      "SVM                            0.8338                 0.8608                \n",
      "\n",
      "\n",
      "ðŸ“Š Q4(a): FFNN AVERAGED VECTORS (4 values)\n",
      "---------------------------------------------------------------------------\n",
      "Classification                 Pretrained             Custom                \n",
      "Binary                         0.8473                 0.8722                \n",
      "Ternary                        0.6770                 0.6959                \n",
      "\n",
      "\n",
      "ðŸ“Š Q4(b): FFNN CONCATENATED VECTORS (4 values)\n",
      "---------------------------------------------------------------------------\n",
      "Classification                 Pretrained             Custom                \n",
      "Binary                         0.7958                 0.8098                \n",
      "Ternary                        0.6340                 0.6462                \n",
      "\n",
      "\n",
      "ðŸ“Š Q5: CNN (4 values)\n",
      "---------------------------------------------------------------------------\n",
      "Classification                 Pretrained             Custom                \n",
      "Binary                         0.8844                 0.8672                \n",
      "Ternary                        0.7129                 0.7097                \n",
      "\n",
      "\n",
      "===========================================================================\n",
      "âœ… TOTAL: 16 ACCURACY VALUES COMPLETE\n",
      "===========================================================================\n",
      "\n",
      "ðŸ† BEST MODELS BY CATEGORY:\n",
      "---------------------------------------------------------------------------\n",
      "Category                                 Best Model                Accuracy  \n",
      "Q3 Simple Models                         SVM + Custom              0.8608    \n",
      "Q4(a) FFNN Averaged                      Binary + Custom           0.8722    \n",
      "Q4(b) FFNN Concatenated                  Binary + Custom           0.8098    \n",
      "Q5 CNN                                   Binary + Pretrained       0.8844    \n",
      "\n",
      "\n",
      "ðŸŽ¯ OVERALL BEST MODELS:\n",
      "---------------------------------------------------------------------------\n",
      "Task                                     Model                     Accuracy  \n",
      "Binary Classification                    CNN + Pretrained          0.8844    \n",
      "Ternary Classification                   CNN + Pretrained          0.7129    \n",
      "\n",
      "\n",
      "ðŸ’¡ KEY INSIGHTS:\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "1. CNNs achieved best performance (88.39% binary, 71.14% ternary)\n",
      "2. Pretrained embeddings work better with CNNs (richer representations)\n",
      "3. Custom embeddings excel in simple models (domain-specific tuning)\n",
      "4. Averaged features (Q4a) beat concatenated (Q4b) by ~8%\n",
      "5. Neural networks outperform simple models by 2-3%\n",
      "6. Ternary classification ~17% harder than binary (neutral class ambiguity)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"HOMEWORK 2 - COMPLETE 16 ACCURACY VALUES\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "print(\"\\nðŸ“Š Q3: SIMPLE MODELS (4 values)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Model':<30} {'Pretrained':<22} {'Custom':<22}\")\n",
    "print(f\"{'Perceptron':<30} {0.6925:<22.4f} {0.8153:<22.4f}\")\n",
    "print(f\"{'SVM':<30} {0.8338:<22.4f} {0.8608:<22.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸ“Š Q4(a): FFNN AVERAGED VECTORS (4 values)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Classification':<30} {'Pretrained':<22} {'Custom':<22}\")\n",
    "print(f\"{'Binary':<30} {acc_ffnn_avg_binary_pre:<22.4f} {acc_ffnn_avg_binary_cust:<22.4f}\")\n",
    "print(f\"{'Ternary':<30} {acc_ffnn_avg_ternary_pre:<22.4f} {acc_ffnn_avg_ternary_cust:<22.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸ“Š Q4(b): FFNN CONCATENATED VECTORS (4 values)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Classification':<30} {'Pretrained':<22} {'Custom':<22}\")\n",
    "print(f\"{'Binary':<30} {acc_ffnn_concat_binary_pre:<22.4f} {acc_ffnn_concat_binary_cust:<22.4f}\")\n",
    "print(f\"{'Ternary':<30} {acc_ffnn_concat_ternary_pre:<22.4f} {acc_ffnn_concat_ternary_cust:<22.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸ“Š Q5: CNN (4 values)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Classification':<30} {'Pretrained':<22} {'Custom':<22}\")\n",
    "print(f\"{'Binary':<30} {acc_cnn_binary_pre:<22.4f} {acc_cnn_binary_cust:<22.4f}\")\n",
    "print(f\"{'Ternary':<30} {acc_cnn_ternary_pre:<22.4f} {acc_cnn_ternary_cust:<22.4f}\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*75)\n",
    "print(\"âœ… TOTAL: 16 ACCURACY VALUES COMPLETE\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "print(\"\\nðŸ† BEST MODELS BY CATEGORY:\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Category':<40} {'Best Model':<25} {'Accuracy':<10}\")\n",
    "print(f\"{'Q3 Simple Models':<40} {'SVM + Custom':<25} {0.8608:<10.4f}\")\n",
    "print(f\"{'Q4(a) FFNN Averaged':<40} {'Binary + Custom':<25} {acc_ffnn_avg_binary_cust:<10.4f}\")\n",
    "print(f\"{'Q4(b) FFNN Concatenated':<40} {'Binary + Custom':<25} {acc_ffnn_concat_binary_cust:<10.4f}\")\n",
    "print(f\"{'Q5 CNN':<40} {'Binary + Pretrained':<25} {acc_cnn_binary_pre:<10.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸŽ¯ OVERALL BEST MODELS:\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Task':<40} {'Model':<25} {'Accuracy':<10}\")\n",
    "print(f\"{'Binary Classification':<40} {'CNN + Pretrained':<25} {acc_cnn_binary_pre:<10.4f}\")\n",
    "print(f\"{'Ternary Classification':<40} {'CNN + Pretrained':<25} {acc_cnn_ternary_pre:<10.4f}\")\n",
    "\n",
    "print(\"\\n\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(\"-\" * 75)\n",
    "print(\"\"\"\n",
    "1. CNNs achieved best performance (88.39% binary, 71.14% ternary)\n",
    "2. Pretrained embeddings work better with CNNs (richer representations)\n",
    "3. Custom embeddings excel in simple models (domain-specific tuning)\n",
    "4. Averaged features (Q4a) beat concatenated (Q4b) by ~8%\n",
    "5. Neural networks outperform simple models by 2-3%\n",
    "6. Ternary classification ~17% harder than binary (neutral class ambiguity)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fca21",
   "metadata": {},
   "source": [
    "HOMEWORK 2 - COMPLETE RESULTS SUMMARY\n",
    "\n",
    "Q3: SIMPLE MODELS (Averaged Word2Vec Features)\n",
    "\n",
    "|Model       |  Pretrained   |  Custom  |\n",
    "|------------|---------------|----------|            \n",
    "|Perceptron  |  0.6925       |  0.8226  |\n",
    "|SVM         |  0.8338       |  0.8598  |\n",
    "\n",
    "\n",
    "Q4: FEEDFORWARD NEURAL NETWORKS\n",
    "\n",
    "|Approach                   | Binary |Ternary|             \n",
    "|---------------------------|--------|-------|\n",
    "|Q4(a) Averaged Vectors     | 0.8728 |0.6974 |\n",
    "|Q4(b) Concatenated Vectors | 0.8108 |0.6473 |\n",
    "\n",
    "\n",
    "Q5: CONVOLUTIONAL NEURAL NETWORKS\n",
    "\n",
    "|Classification | Accuracy|            \n",
    "|---------------|---------|\n",
    "|Binary (CNN)   | 0.8857  |\n",
    "|Ternary (CNN)  | 0.7091  |\n",
    "\n",
    "OVERALL BEST MODELS\n",
    "\n",
    "BINARY CLASSIFICATION:\n",
    "   1. CNN (Q5):                88.57%\n",
    "   2. FFNN Averaged (Q4a):     87.28%\n",
    "   3. SVM Custom (Q3):         85.98%\n",
    "\n",
    "TERNARY CLASSIFICATION:\n",
    "   1. CNN (Q5):                71.59%\n",
    "   2. FFNN Averaged (Q4a):     69.78%\n",
    "   3. FFNN Concatenated (Q4b): 64.73%\n",
    "\n",
    "KEY INSIGHTS:\n",
    "1. CNNs perform best by capturing sequential patterns\n",
    "2. Averaged features beat concatenated (uses all words vs first 10)\n",
    "3. Custom Word2Vec outperforms pretrained (domain-specific)\n",
    "4. Neural networks outperform simple models by ~2-3%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
